{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chapter is all about Maps, Hash Tables and Skip Lists\n",
    "\n",
    "# Recap\n",
    "\n",
    "# Dicts are associative arrays or maps.\n",
    "# They are implemented as hash tables which has a hash code and compression fucntion. \n",
    "# \n",
    "# hash code takes a string and returns an index between -inf and +inf\n",
    "# compression fucntion makes that index in between 0 and N - 1 \n",
    "# where N is the bucket array size.\n",
    "\n",
    "\"\"\"Cool info\"\"\"\n",
    "\n",
    "# Python dicts actually store the hash value for their keys, beacause computing \n",
    "# hash methods each time is costly\n",
    "\n",
    "# Collison handling schemes\n",
    "\n",
    "# SeperatE Chaining or Open Adressingp\n",
    "\n",
    "# seperate chainign is like holding long lists in each slot of the bucket array to avoid coillisons\n",
    "\n",
    "# Open addressing is things like, linear probing, quadratic probing, doublke hsahing.\n",
    "# linear probing - if occupied go next\n",
    "# quadratic probing - if occupied go next but i ^2\n",
    "# double hashing - insert another hash to the calculation\n",
    "\n",
    "\"\"\"Cool info\"\"\"\n",
    "\n",
    "# Python dicts use Open Addressing with a pseudo random number generator.\n",
    "# With load factor threshold 2/3\n",
    "\n",
    "# load factor should NOT go over 1. For python dicts, if it goes over 2/3, \n",
    "# bucket array is resized.\n",
    "\n",
    "# IN default python dictionaries will initialize woth bucket array with size 8\n",
    "\n",
    "\"\"\"Sorted Maps\"\"\"\n",
    "\n",
    "# Keys are sorted.\n",
    "# these are really good for finding nearest keys\\\n",
    "# range queries.\n",
    "\n",
    "# they provide both fast key:value lookups and maintain keys in order.\n",
    "\n",
    "# EXAMPLE - FLIGHT DATABASES \n",
    "\n",
    "\"\"\"Skip Lists\"\"\"\n",
    "\n",
    "# tHEY STORE DATA MORE EFFICIENTLY. \n",
    "# PERFORM operations like insert, delete, search in logarithmic time.\n",
    "\n",
    "# REALLY GOOD\n",
    "# in sorted data management\n",
    "# range queries\n",
    "# they are easier to implement than TREES\n",
    "\n",
    "# BAD\n",
    "# Takes A LOT of memory with all those lists in it\n",
    "# not widely known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR QUESTION R-10.1\n",
    "\n",
    "![MapHierarchy](img/fig102.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "# R-10.1 \n",
    "# Give a concrete implementation of the pop method in the context of the\n",
    "# MutableMapping class, relying only on the five primary abstract methods\n",
    "# of that class\n",
    "\n",
    "# The MutableMapping class is an abstract class in Python's \n",
    "# collections.abc module that provides a framework for creating mutable\n",
    "#  mapping types (like dictionaries). To implement the pop method using\n",
    "#  only the five primary abstract methods of this class, you can\n",
    "#  leverage the following methods:\n",
    "\n",
    "# __getitem__(key): Retrieve an item from the mapping by key\n",
    "# __delitem__(key): Delete an item from the mapping by key.\n",
    "# __iter__(): Return an iterator over the keys of the mapping.\n",
    "# __len__(): Return the number of items in the mapping.\n",
    "# __contains__(key): Check if a key is present in the mapping.\n",
    "\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class MyMapping(MutableMapping):\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Implementing __getitem__ to retrieve an item by key\n",
    "        return self.data[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # Implementing __setitem__ to set an item by key\n",
    "        self.data[key] = value\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        # Implementing __delitem__ to delete an item by key\n",
    "        del self.data[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Implementing __iter__ to iterate over the keys\n",
    "        return iter(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Implementing __len__ to return the number of items\n",
    "        return len(self.data)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        # Implementing __contains__ to check if a key is present\n",
    "        return key in self.data\n",
    "\n",
    "    def pop(self, key, default=None):\n",
    "        # Implementing pop using the five primary abstract methods\n",
    "        if key in self:\n",
    "            value = self[key]\n",
    "            del self[key]\n",
    "            return value\n",
    "        else:\n",
    "            return default\n",
    "\n",
    "# Example usage:\n",
    "my_mapping = MyMapping()\n",
    "my_mapping['a'] = 1\n",
    "my_mapping['b'] = 2\n",
    "\n",
    "print(my_mapping.pop('a', 'Not found'))  # Output: 1\n",
    "print(my_mapping.pop('c', 'Not found'))  # Output: 'Not found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1\n",
      "b: 2\n"
     ]
    }
   ],
   "source": [
    "# R-10.2 \n",
    "# Give a concrete implementation of the items() method in the context of\n",
    "# the MutableMapping class, relying only on the five primary abstract \n",
    "# methods of that class. What would its running time be if directly applied to the\n",
    "# UnsortedTableMap subclass?\n",
    "\n",
    "# The items() method in the context of the MutableMapping class should\n",
    "#  return an iterator over the key-value pairs in the mapping. To implement\n",
    "#  this method using only the five primary abstract methods of the class, you\n",
    "#  can iterate over the keys using the __iter__() method and retrieve\n",
    "#  the corresponding values for each key using the __getitem__(key) method.\n",
    "#  Here's a concrete implementation:\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class MyMapping(MutableMapping):\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        del self.data[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.data\n",
    "\n",
    "    def items(self):\n",
    "        # Implementing items using the five primary abstract methods\n",
    "        return ((key, self[key]) for key in self)\n",
    "\n",
    "# Example usage:\n",
    "my_mapping = MyMapping()\n",
    "my_mapping['a'] = 1\n",
    "my_mapping['b'] = 2\n",
    "\n",
    "for key, value in my_mapping.items():\n",
    "    print(f'{key}: {value}')\n",
    "\n",
    "# Output:\n",
    "# a: 1\n",
    "# b: 2\n",
    "\n",
    "\n",
    "# The items() method implemented in this way has a time complexity\n",
    "#  of O(n), where n is the number of key-value pairs in the mapping.\n",
    "#  This is because it needs to iterate over all keys in the mapping \n",
    "# using the __iter__() method and retrieve the corresponding values\n",
    "#  using the __getitem__(key) method for each key.\n",
    "\n",
    "# If this items() method were directly applied to the UnsortedTableMap\n",
    "#  subclass, the running time would also be O(n), as the underlying data\n",
    "#  structure in UnsortedTableMap is typically an unsorted list, and\n",
    "#  iterating over it and accessing elements by key has linear time\n",
    "#  complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1\n",
      "b: 2\n"
     ]
    }
   ],
   "source": [
    "# R-10.3 \n",
    "# Give a concrete implementation of the items() method directly within the\n",
    "# UnsortedTableMap class, ensuring that the entire iteration runs in O(n)\n",
    "# time.\n",
    "\n",
    "# we can iterate over the list of items in _table and yield the key-value pairs\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "            return self._key < other._key # compare based on keys\n",
    "\n",
    "class UnsortedTableMap(MapBase):\n",
    "    \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Make an empty map.\"\"\"\n",
    "        self._table = [] # list of Item’s\n",
    "\n",
    "    def __getitem__(self, k): \n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                return item._value\n",
    "        raise KeyError(\"Key Error:\" + repr(k)) \n",
    "\n",
    "    def __setitem__(self, k, v): \n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key: # Found a match:\n",
    "                item._value = v # reassign value\n",
    "                return # and quit\n",
    "        # did not find match for key\n",
    "        self._table.append(self._Item(k,v))\n",
    "\n",
    "    def __delitem__(self, k): \n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for j in range(len(self._table)):\n",
    "            if k == self._table[j]. key: # Found a match:\n",
    "                self._table.pop(j) # remove item \n",
    "                return # and quit\n",
    "        raise KeyError(\"Key Error:\" + repr(k)) \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate iteration of the map s keys.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key # yield the KEY\n",
    "\n",
    "    def items(self):\n",
    "        \"\"\"Generate an iteration of key-value pairs (items) in the map.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield (item._key, item._value)\n",
    "\n",
    "\n",
    "my_mapping = UnsortedTableMap()\n",
    "my_mapping['a'] = 1\n",
    "my_mapping['b'] = 2\n",
    "\n",
    "for key, value in my_mapping.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.4 \n",
    "# What is the worst-case running time for inserting n key-value pairs into an\n",
    "# initially empty map M that is implemented with the UnsortedTableMap\n",
    "# class?\n",
    "\n",
    "# The worst-case running time for inserting n key-value pairs into an initially\n",
    "#  empty map implemented with the UnsortedTableMap class is O(n^2).\n",
    "#  This is because, in the worst case, each insertion operation may have to iterate\n",
    "#  through the entire _table list to check for duplicate keys before adding\n",
    "#  the new key-value pair.\n",
    "\n",
    "# Let's break down the worst-case scenario:\n",
    "\n",
    "# Initially, the _table list is empty.\n",
    "# When you perform the first insertion, it takes O(1) time because the list is empty.\n",
    "\n",
    "# For the second insertion, it may have to compare the key with\n",
    "#  one item in the list (1 comparison).\n",
    "\n",
    "# For the third insertion, it may have to compare the key with\n",
    "#  two items in the list (2 comparisons).\n",
    "\n",
    "# For the fourth insertion, it may have to compare the key with three\n",
    "#  items in the list (3 comparisons).\n",
    "\n",
    "# In the worst case, you will perform 1 + 2 + 3 + ... + (n-1) + n = (n*(n+1))/2\n",
    "#  comparisons, which is equivalent to O(n^2) comparisons and time complexity.\n",
    "\n",
    "# So, the worst-case running time for inserting n key-value pairs into an initially empty\n",
    "#  UnsortedTableMap is O(n^2). This is why other data structures like hash tables\n",
    "#  (e.g., Python's dict) are preferred for scenarios where frequent insertions \n",
    "# are required, as they can achieve average-case constant-time insertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.UnsortedTableMap object at 0x7fdd4078cca0>\n",
      "1\n",
      "[('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "# R-10.5 \n",
    "# Reimplement the UnsortedTableMap class from Section 10.1.5, using the\n",
    "# PositionalList class from Section 7.4 rather than a Python list.\n",
    "\n",
    "\n",
    "# This was the Positional List class\n",
    "\n",
    "class DoublyLinkedBase:\n",
    "    \"\"\"A base class providing doubly linked list representation\"\"\"\n",
    "\n",
    "    class _Node:\n",
    "\n",
    "        __slots__ = \"_element\", \"_next\", \"_prev\" # streamline memory usage\n",
    "\n",
    "        def __init__(self, element, next, prev):\n",
    "            self._element = element # element of the node\n",
    "            self._next = next # connect to next node\n",
    "            self._prev = prev # connect to previous node\n",
    "\n",
    "\n",
    "    def __init__(self,):\n",
    "        \"\"\"Make a new DoublyLinkedList\"\"\"\n",
    "        # These nodes are sentries. They never have elements and \n",
    "        # everything happens in between them\n",
    "        self._header =  self._Node(None, None, None)\n",
    "        self._trailer =  self._Node(None, None, None)\n",
    "\n",
    "        # initially no element in the list\n",
    "        self._header._next = self._trailer\n",
    "        self._trailer._prev = self._header\n",
    "        self._size = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._size == 0\n",
    "\n",
    "    def _insert_between (self, e, predecessor, successor):\n",
    "        \"\"\"Add an element between two existing nodes and return the new node\"\"\"\n",
    "        # make a new node\n",
    "        newest = self._Node(e, predecessor, successor)\n",
    "        \n",
    "        # connect to the list\n",
    "        predecessor._next = newest\n",
    "        successor._prev = newest\n",
    "        \n",
    "        self._size += 1\n",
    "        return newest\n",
    "\n",
    "    def _delete_node (self, node):\n",
    "        \"\"\"Delete nonsentinel node from the list and return the nodes element\"\"\"\n",
    "\n",
    "        # find where the the given node in the list \n",
    "        predecessor = node._prev \n",
    "        successor = node._next\n",
    "\n",
    "        # make new connections, jumping over the given node\n",
    "        predecessor._next = successor\n",
    "        successor._prev = predecessor\n",
    "\n",
    "        # decrease size\n",
    "        self._size -=1\n",
    "\n",
    "        element = node._element # get element\n",
    "\n",
    "        node._prev = node._next = node._element = None # depracate Node\n",
    "\n",
    "        return element\n",
    "\n",
    "class PositionalList(DoublyLinkedBase):\n",
    "    \"\"\"A sequential container of elements allowing positional access\"\"\"\n",
    "\n",
    "    # ---------------------nested Position Class ---------------------\n",
    "    class Position:\n",
    "        \"\"\"An abstraction representing the location of a single element\"\"\"\n",
    "        def __init__ (self, container, node):\n",
    "            \"\"\"This should not be invoked directly\"\"\"\n",
    "            self._container = container\n",
    "            self._node = node\n",
    "\n",
    "        def element(self, ):\n",
    "            return self._node._element\n",
    "\n",
    "        def __eq__(self, other) -> bool:\n",
    "            \"\"\"Return True uf other does not represent the same location\"\"\"\n",
    "            return type(other) is type(self) and other._node is self._node\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            \"\"\"Return True if two other does not represent the same location\"\"\"\n",
    "            return not (self == other) # depending on eq, NICE\n",
    "\n",
    "\n",
    "    # --------------------utility method ----------------------------------\n",
    "\n",
    "    def _validate(self,p):\n",
    "        \"\"\"Return position's node, or raise appropiate error if invalid\"\"\"\n",
    "        if not isinstance(p , self.Position):\n",
    "            raise TypeError(\"p must be a Position type object\")\n",
    "        if p._container is not self:\n",
    "            raise ValueError(\"p does not belong to this container\")\n",
    "        if p._node._next is None:           # for deprecated nodes\n",
    "            # this should not be happening, we have sentries\n",
    "            raise ValueError(\"p is no longer valid\")\n",
    "        return p._node\n",
    "\n",
    "    def _make_position(self, node):\n",
    "        \"\"\"Return position instance for a given node, or None if sentinel node\"\"\"\n",
    "        if node is self._header or node is self._trailer:\n",
    "            return None\n",
    "        else:\n",
    "            return self.Position(self, node)\n",
    "\n",
    "    # ----------------------- accessors --------------------------------\n",
    "\n",
    "    def first(self):\n",
    "        \"\"\"Return the first position in the list or None if empty\"\"\"\n",
    "        return self._make_position(self._header._next)\n",
    "\n",
    "    def last(self):\n",
    "        \"\"\"Return the last position in the list or None if empty\"\"\"\n",
    "        return self._make_position(self._trailer._next)\n",
    "\n",
    "    def before(self, p):\n",
    "        \"\"\"Return the position before the given position p , or None if p is first position\"\"\"\n",
    "        node = self._validate(p)\n",
    "        return self._make_position(node._prev)\n",
    "\n",
    "    def after(self, p):\n",
    "        \"\"\"Return the position AFTER the given position p , or None if p is last position\"\"\"\n",
    "        node = self._validate(p)\n",
    "        return self._make_position(node._next)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate a forward iteration of the elements of the list\"\"\"\n",
    "        # First position in the list\n",
    "        cursor = self.first()\n",
    "        while cursor is not None:\n",
    "            # yield the element of that position's Node\n",
    "            yield cursor.element()\n",
    "            cursor = self.after(cursor)\n",
    "\n",
    "    # ------------------------ Mutators --------------------------------\n",
    "\n",
    "    # override inherited version to return position, rather than Node\n",
    "    def _insert_between(self, e, predecessor, successor):\n",
    "        \"\"\"Add element between existing nodes and return new position \"\"\"\n",
    "        node = super()._insert_between(e, predecessor, successor) \n",
    "        return self._make_position(node)\n",
    "\n",
    "    def add_first(self,e):\n",
    "        \"\"\"Insert element e at the front of the list and return new position\"\"\"\n",
    "        return self._insert_between(e, self._header, self._header._next)\n",
    "\n",
    "    def add_last(self,e):\n",
    "        \"\"\"Insert element e at the back of the list and return new position\"\"\"\n",
    "        return self._insert_between(e, self._trailer._prev, self._trailer)\n",
    "\n",
    "    def add_before(self, p, e):\n",
    "        \"\"\"Insert element e into list before Position p and return new position\"\"\"\n",
    "        original = self._validate(p)\n",
    "        return self._insert_between(e, original._prev, original)\n",
    "\n",
    "    def add_after(self, p,e):\n",
    "        \"\"\"Insert element e into list after Position p and return new position\"\"\"\n",
    "        original = self._validate(p)\n",
    "        return self._insert_between(e, original, original._next)\n",
    "\n",
    "    def delete(self, p):\n",
    "        \"\"\"Remove and return element e at position p\"\"\"\n",
    "        original = self._validate(p)\n",
    "        return self._delete_node(original)\n",
    "\n",
    "    def replace(self, p , e):\n",
    "        \"\"\"Replace the element at Position p with e\n",
    "        \n",
    "        Return the element formerly at Position p\"\"\"\n",
    "\n",
    "        original = self._validate(p)\n",
    "        old_value = original._element # temporarily store old element\n",
    "        original._element = e # replace with new element\n",
    "        return old_value # return the old element value\n",
    "\n",
    "\n",
    "# here is the answer\n",
    "\n",
    "\n",
    "class UnsortedTableMap:\n",
    "    \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Make an empty map.\"\"\"\n",
    "        self._table = PositionalList()\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for key, value in self._table:\n",
    "            if k == key:\n",
    "                return value\n",
    "        raise KeyError(\"Key Error: \" + repr(k))\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        for position, (key, value) in self._table:\n",
    "            if k == key:\n",
    "                position.element = (k, v)  # Replace the existing key-value pair\n",
    "                return\n",
    "        # If the key is not found, add it to the list\n",
    "        self._table.add_last((k, v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for position, (key, value) in self._table:\n",
    "            if k == key:\n",
    "                self._table.delete(position)\n",
    "                return\n",
    "        raise KeyError(\"Key Error: \" + repr(k))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate iteration of the map's keys.\"\"\"\n",
    "        for key, _ in self._table:\n",
    "            yield key\n",
    "\n",
    "    def items(self):\n",
    "        \"\"\"Generate an iteration of key-value pairs (items) in the map.\"\"\"\n",
    "        for key, value in self._table:\n",
    "            yield (key, value)\n",
    "\n",
    "\n",
    "map = UnsortedTableMap()\n",
    "\n",
    "map[\"a\"] = 1\n",
    "\n",
    "print(map)\n",
    "print(map[\"a\"])\n",
    "print([elem for elem in map.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# R-10.6 \n",
    "# Which of the hash table collision-handling schemes could tolerate a load\n",
    "# factor above 1 and which could not?\n",
    "\n",
    "# Certainly, let's focus on these specific collision-handling schemes: Separate \n",
    "# Chaining, Open Addressing (including Linear Probing), Robin Hood Hashing, Double\n",
    "#  Hashing, and Quadratic Probing, and discuss their ability to tolerate a load \n",
    "# factor above 1:\n",
    "# \n",
    "\n",
    "# Separate Chaining:\n",
    "# \n",
    "# Tolerance to Load Factor Above 1: Separate chaining can tolerate a \n",
    "# load factor above 1 relatively well. As the load factor increases, the \n",
    "# average length of the linked lists (used to store colliding elements) increases, which\n",
    "#  can lead to slower lookup times but doesn't necessarily cause a fundamental \n",
    "# failure of the data structure. It can handle load factors above 1 without a\n",
    "#  significant issue, but performance may degrade as the load factor becomes much higher.\n",
    "\n",
    "# Open Addressing (Including Linear Probing, Double Hashing, and Quadratic Probing):\n",
    "# \n",
    "# Tolerance to Load Factor Above 1: \n",
    "# \n",
    "# Open addressing schemes \n",
    "# (including Linear Probing, Double Hashing, and Quadratic Probing)\n",
    "#  They may have difficulty \n",
    "# tolerating a load factor above 1, especially when the load factor is significantly\n",
    "#  greater than 1. Open addressing relies on probing for the next available slot when\n",
    "#  a collision occurs. A higher load factor increases the likelihood of clustering\n",
    "#  (groups of keys clustered together), leading to a higher number of collisions and\n",
    "#  potentially significant performance degradation.\n",
    "\n",
    "# Open addressing requires that the load\n",
    "# factor is always at most 1 and that items are stored directly in the cells \n",
    "# of the bucket array itself\n",
    "\n",
    "# Robin Hood Hashing:\n",
    "# \n",
    "# Tolerance to Load Factor Above 1: Robin Hood hashing, which is a variant of\n",
    "#  open addressing, aims to redistribute keys to minimize differences in probing \n",
    "# distances. It can tolerate a load factor slightly above 1 and is designed to\n",
    "#  maintain a relatively balanced distribution of keys. However, as the load factor\n",
    "#  increases significantly, it may still face challenges due to clustering and\n",
    "# increased probing distances.\n",
    "\n",
    "# Double Hashing:\n",
    "# \n",
    "# Tolerance to Load Factor Above 1: Double hashing, another open addressing \n",
    "# scheme, can handle a load factor slightly above 1 but may face challenges\n",
    "#  with a significantly higher load factor. It relies on a secondary hash \n",
    "# function to determine the step size for probing. Careful design and choice \n",
    "# of hash functions can help improve its tolerance to higher load factors.\n",
    "\n",
    "# Quadratic Probing:\n",
    "# \n",
    "# Tolerance to Load Factor Above 1: Quadratic probing, like other open addressing \n",
    "# techniques, may not handle a load factor significantly above 1 effectively due \n",
    "# to clustering. Its performance can degrade as the load factor increases beyond\n",
    "#  a certain threshold.\n",
    "\n",
    "# In summary, separate chaining is relatively robust and can tolerate a load \n",
    "# factor above 1 without fundamental issues. Open addressing schemes, including\n",
    "#  linear probing, double hashing, and quadratic probing, may have difficulty \n",
    "# handling significantly higher load factors and can experience performance \n",
    "# degradation due to clustering. Robin Hood hashing and double hashing can handle\n",
    "#  load factors slightly above 1 with appropriate design and probing strategies.\n",
    "#  The choice of collision-handling scheme should consider the expected load factor \n",
    "# and the trade-offs between memory usage and performance.\n",
    "\n",
    "# Summary from book:\n",
    "\n",
    "# In the hash table schemes described thus far, it is important that the load factor,\n",
    "# λ = n/N, be kept below 1. With separate chaining, as λ gets very close to 1, the\n",
    "# probability of a collision greatly increases, which adds overhead to our operations,\n",
    "# since we must revert to linear-time list-based methods in buckets that have collisions.\n",
    "#  Experiments and average-case analyses suggest that we should maintain\n",
    "# λ < 0.9 for hash tables with separate chaining.\n",
    "\n",
    "# With open addressing, on the other hand, as the load factor λ grows beyond 0.5\n",
    "# and starts approaching 1, clusters of entries in the bucket array start to grow as well.\n",
    "# These clusters cause the probing strategies to “bounce around” the bucket array for\n",
    "# a considerable amount of time before they find an empty slot. In Exercise C-10.36,\n",
    "# we explore the degradation of quadratic probing when λ ≥0.5. Experiments suggest\n",
    "#  that we should maintain λ < 0.5 for an open addressing scheme with linear\n",
    "# probing, and perhaps only a bit higher for other open addressing schemes (for \n",
    "# example, Python’s implementation of open addressing enforces that λ < 2/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Value 2\n",
      "Value 2\n"
     ]
    }
   ],
   "source": [
    "# R-10.7 \n",
    "# \n",
    "# Our Position classes for lists and trees support the __eq__ method so that\n",
    "# two distinct position instances are considered equivalent if they refer to the\n",
    "# same underlying node in a structure. For positions to be allowed as keys\n",
    "# in a hash table, there must be a definition for the hash method that\n",
    "# is consistent with this notion of equivalence. Provide such a hash\n",
    "# method.\n",
    "\n",
    "# To provide a `hash` method for positions that is consistent with the notion of equivalence\n",
    "#  where two distinct position instances are considered equivalent if they refer to\n",
    "#  the same underlying node, you can use the `id()` function to hash the\n",
    "#  underlying node. The `id()` function returns a unique identifier for an object in\n",
    "#  Python. Here's how you can implement the `hash` method for positions:\n",
    "\n",
    "class Position:\n",
    "    \"\"\"An abstraction representing the location of a single element\"\"\"\n",
    "    def __init__ (self, container, node):\n",
    "        \"\"\"This should not be invoked directly\"\"\"\n",
    "        self._container = container\n",
    "        self._node = node\n",
    "    \n",
    "    def element(self, ):\n",
    "        return self._node._element\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        \"\"\"Return True uf other does not represent the same location\"\"\"\n",
    "        return type(other) is type(self) and other._node is self._node\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        \"\"\"Return True if two other does not represent the same location\"\"\"\n",
    "        return not (self == other) # depending on eq, NICE\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Return a hash value based on the unique identifier of the underlying node.\n",
    "        \"\"\"\n",
    "        return hash(id(self._node))\n",
    "\n",
    "# In this implementation, the `hash()` method uses the `id(self._node)` to \n",
    "# obtain a unique identifier for the underlying node, and then it hashes this unique\n",
    "#  identifier. This ensures that two distinct position instances that refer to the\n",
    "#  same underlying node will have the same hash value, satisfying the requirement for\n",
    "#  positions to be allowed as keys in a hash table.\n",
    "\n",
    "# Here's an example of how you can use this `hash` method with positions:\n",
    "\n",
    "# Make two position instances referring to the same node\n",
    "\n",
    "container = {}\n",
    "node = 3\n",
    "\n",
    "position1 = Position(container, node)\n",
    "position2 = Position(container, node)\n",
    "\n",
    "# Check if they are equivalent\n",
    "print(position1 == position2)  # True\n",
    "\n",
    "# Use them as keys in a dictionary\n",
    "position_dict = {}\n",
    "position_dict[position1] = \"Value 1\"\n",
    "position_dict[position2] = \"Value 2\"\n",
    "\n",
    "# Check the dictionary\n",
    "print(position_dict[position1])  # Output: Value 2\n",
    "print(position_dict[position2])  # Output: Value 2\n",
    "\n",
    "# In this example, both `position1` and `position2` refer to the same node, and \n",
    "# their `hash` values are consistent, allowing them to be used as keys in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.8 \n",
    "# What would be a good hash code for a vehicle identification number that\n",
    "# is a string of numbers and letters of the form “9X9XX99X9XX999999,”\n",
    "# where a “9” represents a digit and an “X” represents a letter?\n",
    "\n",
    "# A good hash code for a vehicle identification number (VIN) that is in the \n",
    "# form \"9X9XX99X9XX999999,\" where \"9\" represents a digit and \"X\" represents a\n",
    "#  letter, can be generated by considering both the numeric and alphabetic\n",
    "#  characters. Here's one way to generate a hash code for such a VIN:\n",
    "\n",
    "# Convert the alphabetic characters (X) to their corresponding numeric values.\n",
    "\n",
    "# Concatenate all the numeric and converted alphabetic values into a single string.\n",
    "\n",
    "# Compute the hash code of the resulting string using a suitable hash function.\n",
    "\n",
    "def vin_hash(vin):\n",
    "    # Define a dictionary to map alphabetic characters to numeric values\n",
    "    char_to_num = {'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15,\n",
    "                   'G': 16, 'H': 17, 'J': 18, 'K': 19, 'L': 20, 'M': 21,\n",
    "                   'N': 22, 'P': 23, 'R': 24, 'S': 25, 'T': 26, 'U': 27,\n",
    "                   'V': 28, 'W': 29, 'X': 30, 'Y': 31, 'Z': 32}\n",
    "\n",
    "    # Convert alphabetic characters to numeric values and concatenate\n",
    "    numeric_vin = ''.join(str(char_to_num[c]) if c in char_to_num else c for c in vin)\n",
    "\n",
    "    # Compute the hash code of the resulting string\n",
    "    hash_code = hash(numeric_vin)\n",
    "\n",
    "    return hash_code\n",
    "\n",
    "# This vin_hash function converts alphabetic characters to numeric values based \n",
    "# on the dictionary char_to_num, then concatenates all the characters to form\n",
    "#  a numeric string, and finally computes the hash code of the resulting string \n",
    "# using Python's built-in hash function.\n",
    "\n",
    "# Keep in mind that the quality of the hash code may depend on the distribution of \n",
    "# VINs you expect to encounter in practice. If there are specific constraints\n",
    "#  or patterns in the VINs, you might need to adjust the hashing approach accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.9 \n",
    "# Draw the 11-entry hash table that results from using the hash function,\n",
    "# h(i) = ( 3i+ 5) mod 11, to hash the keys 12, 44, 13, 88, 23, 94, 11, 39, 20,\n",
    "# 16, and 5, assuming collisions are handled by chaining.\n",
    "\n",
    "# To draw the 11-entry hash table resulting from using the hash function h(i) = (3i + 5) \\mod 11\n",
    "# h(i)=(3i+5)mod11 to hash the given keys (12, 44, 13, 88, 23, 94, 11, 39, 20, 16, and 5) with\n",
    "#  collisions handled by chaining, you can calculate the hash values for each key and place\n",
    "#  them in the appropriate slot in the hash table.\n",
    "\n",
    "# Key 12 hashes to h(12) = (3 * 12 + 5) \\ mod 11 = 8, so it is placed in Index 8.\n",
    "# Key 44 hashes to h(44) = (3 * 44 + 5) \\ mod 11 = 5, so it is placed in Index 5.\n",
    "# Key 13 hashes to h(13) = (3 * 13 + 5) \\ mod 11 = 0, so it is placed in Index 0.\n",
    "# Key 88 hashes to h(88) = (3 * 88 + 5) \\ mod 11 = 5, so it is placed in Index 5.\n",
    "# Key 23 hashes to h(23) = (3 * 23 + 5) \\ mod 11 = 10, so it is placed in Index 10.\n",
    "# Key 94 hashes to h(94) = (3 * 94 + 5) \\ mod 11 = 1, so it is placed in Index 1.\n",
    "# Key 11 hashes to h(11) = (3 * 11 + 5) \\ mod 11 = 5, so it is placed in Index 5.\n",
    "# Key 39 hashes to h(39) = (3 * 39 + 5) \\ mod 11 = 7, so it is placed in Index 7.\n",
    "# Key 20 hashes to h(20) = (3 * 20 + 5) \\ mod 11 = 10, so it is placed in Index 10.\n",
    "# Key 16 hashes to h(16) = (3 * 16 + 5) \\ mod 11 = 9, so it is placed in Index 9.\n",
    "# Key 5 hashes to h(5) = (3 * 5 + 5) \\ mod 11 = 9, so it is placed in Index 9. \n",
    "\n",
    "# Index 0: [13]\n",
    "# Index 1: [94]\n",
    "# Index 2: []\n",
    "# Index 3: []\n",
    "# Index 4: []\n",
    "# Index 5: [44, 88, 11]\n",
    "# Index 6: []\n",
    "# Index 7: [39]\n",
    "# Index 8: [12]\n",
    "# Index 9: [16, 5]\n",
    "# Index 10: [20, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.10 \n",
    "# What is the result of the previous exercise, assuming \n",
    "# collisions are handled by linear probing?\n",
    "\n",
    "# Lets insert the keys one by one.\n",
    "\n",
    "# key 12 - index 8\n",
    "# key 44 - index 5\n",
    "# key 13 - index 0 \n",
    "# key 88 - index 5  - not empty - index 6\n",
    "# key 23 - index 10 \n",
    "# key 94 - index 1\n",
    "# key 11 - index 5 - not empty - index 6 - not empty - index 7\n",
    "# key 39 - index 7 - not empty - index 8 - not empty - index 9\n",
    "# key 20 - index 10 - not empty - index 0 - not empty - index 1 - not empty - index 2\n",
    "# key 16 - index 9 - not empty - index 0 - not empty - index 1 - not empty \n",
    "#                           - index 2 - not empty - index 3\n",
    "# key 5 - index 9   - not empty - index 0 - not empty - index 1 - not empty \n",
    "#                           - index 2 - not empty - index 3 - not empty - index 4\n",
    "\n",
    "# Index 0: [13] \n",
    "# Index 1: [94]\n",
    "# Index 2: [20]\n",
    "# Index 3: [16]\n",
    "# Index 4: [5]\n",
    "# Index 5: [44]\n",
    "# Index 6: [88]\n",
    "# Index 7: [11]\n",
    "# Index 8: [12]\n",
    "# Index 9: [39]\n",
    "# Index 10: [23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 0, 5, 8, 1, 5, 1, 10, 9, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-10.11 \n",
    "# Show the result of Exercise R-10.9, assuming collisions are handled by\n",
    "# quadratic probing, up to the point where the method fails.\n",
    "\n",
    "def calculate(seq):\n",
    "    result = []\n",
    "    for elem in seq:\n",
    "        result.append(((elem * 3)+5) % 11)\n",
    "    return result\n",
    "\n",
    "calculate([12, 44, 13, 88, 23, 94, 11, 39, 20, 16, 5])\n",
    "# [8, 5, 0, 5, 8, 1, 5, 1, 10, 9, 9]\n",
    "\n",
    "# Quadratic probing is a collision resolution technique used in hash tables to find\n",
    "#  an available slot when a collision occurs. When multiple keys hash to the same\n",
    "#  index, quadratic probing attempts to find the next available index by using a\n",
    "#  quadratic sequence of indices, rather than simply linearly probing (i.e., checking\n",
    "#  the next index and then the one after that).\n",
    "\n",
    "# Here's how quadratic probing works:\n",
    "\n",
    "# 1) Calculate the initial hash index for the key.\n",
    "\n",
    "# 2) If the calculated index is already occupied by another key, start a quadratic\n",
    "#  sequence of probes. The sequence is typically generated using the formula \n",
    "# i^2i  for increasing values of ii. So, you start with i = 1 for the first\n",
    "#  probe, i = 2 for the second probe, i = 3 for the third probe, and so on.\n",
    "\n",
    "# 3) Calculate the new index by adding (i^2) to the original index.\n",
    "\n",
    "# 4) Check if the new index is within the bounds of the hash table. If it\n",
    "#  is, and the slot is empty, insert the key at that index. If it's occupied, continue\n",
    "#  the quadratic probing sequence with the next i.\n",
    "\n",
    "# 5) Repeat steps 3 and 4 until an empty slot is found or the entire hash table is \n",
    "# searched (in which case, it is considered full).\n",
    "\n",
    "# here are the results for quadratic probing\n",
    "\n",
    "# Key 12 hashes to h(12) = 8h(12)=8 and is placed at Index 8.\n",
    "\n",
    "# Key 44 hashes to h(44) = 5h(44)=5, but Index 5 is occupied by Key 23. Quadratic \n",
    "# probing moves to Index 9, where Key 44 is placed.\n",
    "\n",
    "# Key 13 hashes to h(13) = 0h(13)=0 and is placed at Index 0.\n",
    "\n",
    "# Key 88 hashes to h(88) = 4h(88)=4, but Index 4 is occupied by Key 23. Quadratic\n",
    "#  probing moves to Index 9 (occupied by Key 44), then to Index 0, where Key 88 is placed.\n",
    "\n",
    "# Key 23 hashes to h(23) = 10h(23)=10, but Index 10 is occupied by Key 12. Quadratic probing\n",
    "#  moves to Index 0 (occupied by Key 13), then to Index 3, where Key 23 is placed.\n",
    "\n",
    "# Key 94 hashes to h(94) = 1h(94)=1 and is placed at Index 1.\n",
    "\n",
    "# Key 11 hashes to h(11) = 5h(11)=5, but Index 5 is occupied by Key 23. Quadratic\n",
    "#  probing moves to Index 9 (occupied by Key 44), then to Index 0 (occupied by\n",
    "#  Key 13), and finally to Index 8, where Key 11 is placed.\n",
    "\n",
    "# Key 39 hashes to h(39) = 7h(39)=7 and is placed at Index 7.\n",
    "\n",
    "# Key 20 hashes to h(20) = 10h(20)=10, but Index 10 is occupied by Key 23. Quadratic\n",
    "#  probing moves to Index 0 (occupied by Key 13), then to Index 3 (occupied by Key\n",
    "#  23), and finally to Index 8 (occupied by Key 11). It fails to find an empty slot.\n",
    "\n",
    "# Key 16 hashes to h(16) = 9h(16)=9, but Index 9 is occupied by Key 39. Quadratic probing\n",
    "#  moves to Index 0 (occupied by Key 13), then to Index 3 (occupied by Key 23), then\n",
    "#  to Index 8 (occupied by Key 11), and finally to Index 1, where Key 16 is placed.\n",
    "\n",
    "# Key 5 hashes to h(5) = 9h(5)=9, but Index 9 is occupied by Key 39. Quadratic probing \n",
    "# moves to Index 0 (occupied by Key 13), then to Index 3 (occupied by Key 23), then to\n",
    "#  Index 8 (occupied by Key 11), then to Index 1 (occupied by Key 16), and finally to\n",
    "#  Index 4, where Key 5 is placed.\n",
    "\n",
    "\n",
    "# Index 0: 13\n",
    "# Index 1: 94\n",
    "# Index 2: \n",
    "# Index 3: 23\n",
    "# Index 4: 5\n",
    "# Index 5: \n",
    "# Index 6: \n",
    "# Index 7: 39\n",
    "# Index 8: 11\n",
    "# Index 9: 16\n",
    "# Index 10: 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# R-10.12 \n",
    "# What is the result of Exercise R-10.9 when collisions are handled by \n",
    "# double hashing using the secondary hash function h′(k) = 7 − (k mod 7)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.13 \n",
    "# What is the worst-case time for putting n entries in an initially empty hash\n",
    "# table, with collisions resolved by chaining? What is the best case?\n",
    "\n",
    "# all hashes collide - worst case\n",
    "\n",
    "# Worst-case time: In the worst-case scenario, all n entries hash to the same \n",
    "# index in the table, resulting in a long chain of collisions. This can lead to\n",
    "#  the hash table essentially degenerating into a linked list. In this worst-case \n",
    "# scenario, the time complexity for putting n entries is O(n), as each insertion\n",
    "#  into the chain takes O(1) time, but there are n entries to insert.\n",
    "\n",
    "# Best-case time: In the best-case scenario, the hash function distributes the n \n",
    "# entries evenly across the hash table, and there are no collisions. Each insertion \n",
    "# into the table takes O(1) time in the best case, as there are no collisions to \n",
    "# resolve. Therefore, the best-case time complexity for putting n entries is O(n), which\n",
    "#  is the same as the worst-case when using chaining.\n",
    "\n",
    "# It's important to note that the actual performance of a hash table can vary depending\n",
    "#  on factors such as the quality of the hash function and the load factor (the ratio\n",
    "#  of the number of entries to the size of the table). In practice, a well-designed\n",
    "#  hash function and proper resizing of the table can help minimize collisions and \n",
    "# achieve good average-case performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR QUESTION R-10.14\n",
    "\n",
    "![MapHierarchy](img/fig106.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Work\n",
    "\n",
    "# R-10.14 \n",
    "# Show the result of rehashing the hash table shown i  n Figure 10.6 into a\n",
    "# table of size 19 using the new hash function h(k) = 3k mod 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.15 \n",
    "# Our HashMapBase class maintains a load factor λ ≤0.5. Reimplement\n",
    "# that class to allow the user to specify the maximum load, and adjust the\n",
    "# concrete subclasses accordingly.\n",
    "\n",
    "# This was the original implementation \n",
    "\n",
    "from random import randrange\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "# Here is the answer\n",
    "# Only the setitem method will change\n",
    "# Additinally we can define load factor function to make code cleaner.\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "\n",
    "    def __init__(self, cap=11, max_load=0.5, p=109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0  # Number of entries in the map\n",
    "        self._prime = p  # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p - 1)  # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)  # shift from 0 to p-1 for MAD\n",
    "        # setup instance variable\n",
    "        self._max_load = max_load  # Maximum load factor\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k) * self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def _load_factor(self):\n",
    "        return self._n / len(self._table)\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)  # subroutine maintains self._n\n",
    "        if self._load_factor() > self._max_load:\n",
    "            self._resize(2 * len(self._table) - 1)  # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):  # resize bucket array to capacity c\n",
    "        old = list(self.items())  # use iteration to record existing items\n",
    "        self._table = c * [None]  # reset the table to desired capacity\n",
    "        self._n = 0  # n recomputed during subsequent adds\n",
    "        for (k, v) in old:\n",
    "            self[k] = v  # reinsert old key-value pairs\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)  # may Raise KeyError\n",
    "        self._n -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.16 \n",
    "# Give a pseudo-code description of an insertion into a hash table that uses\n",
    "# quadratic probing to resolve collisions, assuming we also use the trick of\n",
    "# replacing deleted entries with a special “deactivated entry” object\n",
    "\n",
    "# lets remember quadratic probing first\n",
    "\n",
    "# Quadratic probing is a collision resolution technique used in hash tables to find\n",
    "#  an available slot when a collision occurs. When multiple keys hash to the same\n",
    "#  index, quadratic probing attempts to find the next available index by using a\n",
    "#  quadratic sequence of indices, rather than simply linearly probing (i.e., checking\n",
    "#  the next index and then the one after that).\n",
    "\n",
    "# Here's how quadratic probing works:\n",
    "\n",
    "# 1) Calculate the initial hash index for the key.\n",
    "\n",
    "# 2) If the calculated index is already occupied by another key, start a quadratic\n",
    "#  sequence of probes. The sequence is typically generated using the formula \n",
    "# i^2i  for increasing values of i. So, you start with i = 1 for the first\n",
    "#  probe, i = 2 for the second probe, i = 3 for the third probe, and so on.\n",
    "\n",
    "# 3) Calculate the new index by adding (i^2) to the original index.\n",
    "\n",
    "# 4) Check if the new index is within the bounds of the hash table. If it\n",
    "#  is, and the slot is empty, insert the key at that index. If it's occupied, continue\n",
    "#  the quadratic probing sequence with the next i.\n",
    "\n",
    "# 5) Repeat steps 3 and 4 until an empty slot is found or the entire hash table is \n",
    "# searched (in which case, it is considered full).\n",
    "\n",
    "# here is the code and a description of an insertion into a hash table that uses\n",
    "#  quadratic probing to resolve collisions and replaces deleted entries with a \n",
    "# special \"deactivated entry\" object:\n",
    "\n",
    "class HashTable:\n",
    "    \"\"\"Construct a hash table upon Python lists - dynamic arrays\"\"\"\n",
    "    def __init__(self, size):\n",
    "        # Initialize a hash table with the given size\n",
    "        self.size = size\n",
    "        self.table = [None] * size\n",
    "\n",
    "    def hash_function(self, key):\n",
    "        # Calculate the initial hash index for the key\n",
    "        return hash(key) % self.size\n",
    "\n",
    "    def quadratic_probe(self, index, i):\n",
    "        # Calculate the new index using quadratic probing\n",
    "        return (index + i * i) % self.size\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        index = self.hash_function(key)\n",
    "        i = 0\n",
    "\n",
    "        while i < self.size:\n",
    "            new_index = self.quadratic_probe(index, i)\n",
    "\n",
    "            if self.table[new_index] is None or self.table[new_index].is_deactivated():\n",
    "                # If the slot is empty or contains a deactivated entry, insert the new entry\n",
    "                self.table[new_index] = Entry(key, value)\n",
    "                return True\n",
    "            elif self.table[new_index].is_deleted():\n",
    "                # If the slot contains a deleted entry, replace it with the new entry\n",
    "                self.table[new_index] = Entry(key, value)\n",
    "                return True\n",
    "            else:\n",
    "                # Collision occurred, continue probing\n",
    "                i += 1\n",
    "\n",
    "        # If the loop completes without finding an empty slot, the table is full\n",
    "        return False\n",
    "\n",
    "    def delete(self, key):\n",
    "        index = self.hash_function(key)\n",
    "        i = 0\n",
    "\n",
    "        while i < self.size:\n",
    "            new_index = self.quadratic_probe(index, i)\n",
    "\n",
    "            if self.table[new_index] is None:\n",
    "                # Key not found\n",
    "                return False\n",
    "            elif self.table[new_index].key == key:\n",
    "                # Mark the entry as deleted\n",
    "                self.table[new_index].mark_as_deleted()\n",
    "                return True\n",
    "            else:\n",
    "                # Collision occurred, continue probing\n",
    "                i += 1\n",
    "\n",
    "        # Key not found\n",
    "        return False\n",
    "\n",
    "class Entry:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.deleted = False\n",
    "\n",
    "    def is_deleted(self):\n",
    "        return self.deleted\n",
    "\n",
    "    def is_deactivated(self):\n",
    "        return self.deleted\n",
    "\n",
    "    def mark_as_deleted(self):\n",
    "        self.deleted = True\n",
    "\n",
    "# Description: \n",
    "\n",
    "# HashTable is the class representing the hash table with quadratic probing.\n",
    "\n",
    "# hash_function calculates the initial hash index for the key. - Hash method returns an INTEGER\n",
    "\n",
    "# quadratic_probe calculates the new index using quadratic probing.\n",
    "\n",
    "# insert method inserts a key-value pair into the hash table, using quadratic probing\n",
    "#  to resolve collisions. If a slot is empty or contains a deactivated entry, it\n",
    "#  inserts the new entry. If it encounters a deleted entry, it replaces it with the new entry.\n",
    "\n",
    "# delete method marks an entry as deleted if it matches the specified key.\n",
    "\n",
    "# Entry is a class representing entries in the hash table. Each entry contains a \n",
    "# key, value, and a flag to indicate if it's deleted or deactivated. Deleted entries\n",
    "#  are treated as deactivated.\n",
    "\n",
    "# This approach ensures that deleted entries are replaced with a \n",
    "# special \"deactivated entry\" object, allowing them to be reused for future insertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.17 \n",
    "# \n",
    "# Modify our ProbeHashMap to use quadratic probing.\n",
    "\n",
    "# Here is our subclasses.\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object() # sentinel object that marks locations of previous deletions\n",
    "\n",
    "    def _is_avaliable(self):\n",
    "        \"\"\"Return True if index j is avaliable in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "\n",
    "    def _find_slot(self, j ,k):\n",
    "        r\"\"\"\n",
    "        Search for key k in bucket at index j.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_avaliable(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j                          # mark this as first avail\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail)              # search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)                            # found a match\n",
    "            j = (j + 1) % len(self._table)                  # keep looking (cyclically)\n",
    "\n",
    "    def bucket_getitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        return self._table[s]._value\n",
    "\n",
    "    def bucket_setitem(self, j, k, v): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v)                # insert new item\n",
    "            self._n += 1                                    # size has increased\n",
    "        else:\n",
    "            self._table[s]._value = v                       # overwrite existing\n",
    "\n",
    "    def bucket_delitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL                # mark as vacated\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self. table)):                   # scan entire table\n",
    "            if not self._is_avaliable(j):\n",
    "                yield self._table[j]._key\n",
    "\n",
    "\n",
    "# answer - only _find_slot will change\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object() # sentinel object that marks locations of previous deletions\n",
    "\n",
    "    def _is_avaliable(self, j):\n",
    "        \"\"\"Return True if index j is avaliable in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "\n",
    "    def _find_slot(self, j, k):\n",
    "        r\"\"\"\n",
    "        Search for key k in bucket at index j using quadratic probing.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match is found, success is False and index denotes the first available slot.\n",
    "        \"\"\"\n",
    "        first_avail = None\n",
    "        count = 0  # Counter for quadratic probing\n",
    "\n",
    "        while True:\n",
    "            if self._is_avaliable(j):\n",
    "                if first_avail is None:\n",
    "                    first_avail = j  # Mark this as the first available slot\n",
    "                if self._table[j] is None:\n",
    "                    return (False, first_avail)  # Search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)  # Found a match\n",
    "\n",
    "            # Quadratic probing: j + count^2\n",
    "            count += 1\n",
    "            j = (j + count**2) % len(self._table)  # Keep looking (cyclically)\n",
    "\n",
    "    def bucket_getitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        return self._table[s]._value\n",
    "\n",
    "    def bucket_setitem(self, j, k, v): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v)                # insert new item\n",
    "            self._n += 1                                    # size has increased\n",
    "        else:\n",
    "            self._table[s]._value = v                       # overwrite existing\n",
    "\n",
    "    def bucket_delitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL                # mark as vacated\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self. table)):                   # scan entire table\n",
    "            if not self._is_avaliable(j):\n",
    "                yield self._table[j]._key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.18 \n",
    "# \n",
    "# Explain why a hash table is not suited to implement a sorted map\n",
    "\n",
    "# First of all, what is a sorted map?\n",
    "\n",
    "# The traditional map ADT allows a user to look up the value associated with a given\n",
    "# key, but the search for that key is a form known as an exact search.\n",
    "\n",
    "# Map ADT does not provide any way to get a list of all events ordered by the time at\n",
    "# which they occur, or to search for which event occurred closest to a particular time.\n",
    "# In fact, the fast performance of hash-based implementations of the map ADT relies\n",
    "# on the intentionally scattering of keys that may seem very “near” to each other in\n",
    "# the original domain, so that they are more uniformly distributed in a hash table.\n",
    "\n",
    "# here are some methods for it\n",
    "# M.find min( ): Return the (key,value) pair with minimum key (or None, if map is empty).\n",
    "# M.find max( ): Return the (key,value) pair with maximum key (or None, if map is empty).\n",
    "\n",
    "# M.find lt(k): Return the (key,value) pair with the greatest key that\n",
    "# is strictly less than k (or None, if no such item exists). \n",
    "# M.find le(k): Return the (key,value) pair with the greatest key that\n",
    "# is less than or equal to k (or None, if no such item exists).\n",
    "\n",
    "# M.find gt(k): Return the (key,value) pair with the least key that is\n",
    "# strictly greater than k (or None, if no such item exists). \n",
    "# M.find ge(k): Return the (key,value) pair with the least key that is\n",
    "# greater than or equal to k (or None, if no such item). \n",
    "\n",
    "# M.find range(start, stop): Iterate all (key,value) pairs with start <= key < stop.\n",
    "# If start is None, iteration begins with minimum key; if\n",
    "# stop is None, iteration concludes with maximum key.\n",
    "\n",
    "# iter(M): Iterate all keys of the map according to their natural\n",
    "# order, from smallest to largest.\n",
    "# reversed(M):\n",
    "\n",
    "# the answer\n",
    "\n",
    "# A hash table is not well-suited to implement a sorted map for several reasons:\n",
    "\n",
    "\"\"\" Lack of Natural Ordering:\"\"\" \n",
    "# Hash tables are inherently unordered data structures. They\n",
    "#  store key-value pairs based on the hash values of keys, and this arrangement \n",
    "# doesn't provide any inherent order. In contrast, a sorted map requires that the\n",
    "#  elements be stored in a specific order based on their keys.\n",
    "\n",
    "\"\"\"Inefficient for Range Queries:\"\"\"\n",
    "# #  Sorted maps often require efficient support for range\n",
    "#  queries, such as finding all keys within a given range. Hash tables do not provide\n",
    "#  a natural way to perform such queries without iterating over all entries, which can\n",
    "#  be inefficient.\n",
    "\n",
    "\"\"\"Extra Overhead:\"\"\" \n",
    "# Implementing a sorted map using a hash table would require additional \n",
    "# data structures or operations to maintain the sorted order of keys. This added \n",
    "# complexity can lead to increased memory usage and slower performance compared\n",
    "#  to data structures explicitly designed for sorting, like balanced search\n",
    "#  trees (e.g., AVL trees or Red-Black trees).\n",
    "\n",
    "\"\"\" Difficulty in Maintaining Sorting Order:\"\"\" \n",
    "# While you could potentially sort the keys\n",
    "#  of a hash table after each insertion, this would be inefficient for large data \n",
    "# sets. Additionally, maintaining the sorted order during insertions, deletions, and\n",
    "#  updates would be a challenging task and could lead to performance degradation.\n",
    "\n",
    "\"\"\"Loss of Constant-Time Access:\"\"\" \n",
    "# One of the primary advantages of hash tables is their\n",
    "#  constant-time average-case access time (O(1)). Implementing sorting and maintaining\n",
    "#  it would likely result in a loss of this constant-time guarantee for certain operations.\n",
    "\n",
    "# For implementing a sorted map, data structures like balanced search trees (e.g., Red-Black\n",
    "#  trees or AVL trees) or skip lists are better-suited choices. These structures \n",
    "# inherently maintain order, support efficient range queries, and provide a natural\n",
    "#  way to insert, delete, and retrieve elements while keeping the elements sorted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.19 \n",
    "# Describe how a sorted list implemented as a doubly linked list could be\n",
    "# used to implement the sorted map ADT.\n",
    "\n",
    "# A sorted list implemented as a doubly linked list can be used as a foundational data\n",
    "#  structure to implement the sorted map ADT (Abstract Data Type). \n",
    "# Here's how it can be achieved:\n",
    "\n",
    "\"\"\"Data Structure for the Sorted List:\"\"\"\n",
    "\n",
    "\"\"\"Doubly Linked List:\"\"\" \n",
    "# Use a doubly linked list to maintain the elements of \n",
    "# the sorted list. Each node of the linked list contains a key-value pair.\n",
    "\n",
    "\"\"\"Sorted Order:\"\"\" \n",
    "# Ensure that the elements in the linked list are arranged in\n",
    "#  sorted order based on the keys. The keys should be used as the criteria \n",
    "# for sorting.\n",
    "\n",
    "\"\"\"Operations for Implementing Sorted Map:\"\"\"\n",
    "\n",
    "\"\"\"Insertion:\"\"\" \n",
    "# When inserting a new key-value pair into the sorted map, you can perform\n",
    "#  an insertion operation into the sorted list. To maintain the sorted order, find\n",
    "#  the correct position in the linked list for the new key and insert it there. \n",
    "# This may involve traversing the list to find the appropriate location.\n",
    "\n",
    "\"\"\"Deletion:\"\"\" \n",
    "# To delete a key-value pair with a specific key, search for the key in the linked \n",
    "# list and remove the corresponding node if found.\n",
    "\n",
    "\"\"\"Search:\"\"\" \n",
    "# To search for a key in the sorted map, traverse the linked \n",
    "# list in sorted order, comparing the keys at each step until you find the key \n",
    "# you are looking for.\n",
    "\n",
    "\"\"\"Range Queries:\"\"\" \n",
    "# Since the elements are already sorted, implementing range queries (e.g., finding all\n",
    "#  key-value pairs within a specified range of keys) becomes straightforward. You can \n",
    "# traverse the list and select the elements that fall within the desired range.\n",
    "\n",
    "\"\"\"Iteration in Sorted Order:\"\"\" \n",
    "# When iterating through the sorted map, you can start at the head or tail of the linked \n",
    "# list, depending on whether you want to iterate in ascending or descending order. Then, simply \n",
    "# traverse the linked list, visiting each key-value pair in sorted order.\n",
    "\n",
    "\"\"\"Complexity Analysis:\"\"\"\n",
    "\n",
    "\"\"\"Insertion and Deletion:\"\"\" \n",
    "# In the worst case, both insertion and deletion operations may require traversing the entire \n",
    "# linked list, resulting in O(n) time complexity, where n is the number of elements in the sorted map.\n",
    "\n",
    "\"\"\"Search:\"\"\" \n",
    "# Searching for a specific key in the sorted map also has a worst-case time complexity of O(n)\n",
    "#  due to the need to traverse the list.\n",
    "\n",
    "\"\"\"Range Queries and Iteration:\"\"\"\n",
    "#  Both range queries and iterating in sorted order are efficient operations, as they involve \n",
    "# traversing only the relevant portion of the linked list.\n",
    "\n",
    "\"\"\"Advantages:\"\"\"\n",
    "\n",
    "# Simplicity: Implementing a sorted map with a sorted list is conceptually straightforward.\n",
    "# Range Queries: It efficiently supports range query operations due to the inherent sorting.\n",
    "# Iteration in Order: Elements can be efficiently iterated in sorted order.\n",
    "\n",
    "\"\"\"Disadvantages:\"\"\"\n",
    "\n",
    "# Inefficient for Insertions and Deletions: The worst-case time complexity for insertions\n",
    "#  and deletions is O(n), which can be inefficient for large datasets.\n",
    "# Space Overhead: Each element requires extra space for the doubly linked list pointers.\n",
    "\n",
    "# In summary, a sorted list implemented as a doubly linked list is a viable option for\n",
    "#  implementing a sorted map ADT, but it may not be the most efficient choice for scenarios\n",
    "#  with frequent insertions and deletions. For those cases, balanced search trees \n",
    "# (e.g., Red-Black trees or AVL trees) may provide better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.20 \n",
    "# What is the worst-case asymptotic running time for performing n deletions\n",
    "# from a SortedTableMap instance that initially contains 2n entries?\n",
    "\n",
    "# n deletions.\n",
    "# for each deletion, the time complexity can be o(n) in the worst case.\n",
    "# this is just for traversing through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR QUESTION 10.21\n",
    "\n",
    "![Analysis of SortedTableMap](img/table103.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.21 \n",
    "# Consider the following variant of the find index method from Code \n",
    "# Fragment 10.8, in the context of the SortedTableMap class:\n",
    "\n",
    "def _find_index(self, k, low, high): \n",
    "    \"\"\"In contrast, the provided variant of _find_index recursively calls\n",
    "     itself with a new range that includes both the upper and lower halves\n",
    "      when the key at mid is less than k. This means that it might not\n",
    "       return the index of the first occurrence of k but rather the index\n",
    "    of the last occurrence of k.\"\"\"\n",
    "    if high < low:\n",
    "        return high + 1\n",
    "    else:\n",
    "        mid = (low + high) // 2\n",
    "        if self._table[mid]._key < k:\n",
    "            return self._find_index(k, mid + 1, high)\n",
    "        else:\n",
    "            return self._find_index(k, low, mid -1)\n",
    "\n",
    "# Does this always produce the same result as the original version? Justify your answer.\n",
    "\n",
    "# This was the original version of the class\n",
    "\n",
    "class SortedTableMap(MapBase):\n",
    "    \"\"\"\n",
    "    Map implementation using a sorted table.\n",
    "    \"\"\"\n",
    "    # nonpublic behaviors\n",
    "    def _find_index(self, k, low, high):\n",
    "        \"\"\"\n",
    "        Return index of the leftmost item with key greater than or equal to k.\n",
    "        Return high + 1 if no such item qualifies.\n",
    "        That is, j will be returned such that:\n",
    "            all items of slice table[low:j] have key < k\n",
    "            all items of slice table[j:high+1] have key >= k\n",
    "        \"\"\"\n",
    "        if high < low:\n",
    "            # no element qualifies\n",
    "            return high + 1\n",
    "        else:\n",
    "            mid = (low + high) // 2\n",
    "            if k == self._table[mid]._key:\n",
    "                # found exact match\n",
    "                return mid\n",
    "            elif k < self._table[mid]._key:\n",
    "                # note: may return mid\n",
    "                return self._find_index(k, low, mid - 1)\n",
    "            else:\n",
    "                # answer is right of mid\n",
    "                return self._find_index(k, mid + 1, high)\n",
    "\n",
    "    # public behaviors\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Make an empty map.\n",
    "        \"\"\"\n",
    "        self._table = []\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return number of items in the map.\n",
    "        \"\"\"\n",
    "        return len(self._table)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"\n",
    "        Return value associated with key k (raise KeyError if not found).\n",
    "        \"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j == len(self._table) or self._table[j]._key != k:\n",
    "            raise KeyError('Key Error:' + repr(k))\n",
    "        return self._table[j]._value\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"\n",
    "        Assign value v to key k, overwriting existing value if present.\n",
    "        \"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j < len(self._table) and self._table[j]._key == k:\n",
    "            # reassign value\n",
    "            self._table[j]._value = v\n",
    "        else:\n",
    "            # adds new item\n",
    "            self._table.insert(j, self._Item(k, v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"\n",
    "        Remove item associated with key k (raise KeyError if not found).\n",
    "        \"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j == len(self._table) or self._table[j]._key != k:\n",
    "            raise KeyError('Key Error: ' + repr(k))\n",
    "        # delete item\n",
    "        self._table.pop(j)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Generate keys of the map ordered from minimum to maximum.\n",
    "        \"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key\n",
    "\n",
    "    def __reversed__(self):\n",
    "        \"\"\"\n",
    "        Generate keys of the map ordered from maximum to minimum.\n",
    "        \"\"\"\n",
    "        for item in reversed(self._table):\n",
    "            yield item._key\n",
    "\n",
    "    def find_min(self):\n",
    "        \"\"\"\n",
    "        Return (key, value) pair with minimum key (or None if empty).\n",
    "        \"\"\"\n",
    "        if len(self._table) > 0:\n",
    "            return (self._table[0]._key, self._table[0]._value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_max(self):\n",
    "        \"\"\"\n",
    "        Return (key, value) pair with maximum key (or None if empty).\n",
    "        \"\"\"\n",
    "        if len(self._table) > 0:\n",
    "            return (self._table[-1]._key, self._table[-1]._value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_ge(self, k):\n",
    "        \"\"\"\n",
    "        Return (key, value) pair with least key greater than or equal to k.\n",
    "        \"\"\"\n",
    "        # j's key >= k\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j < len(self._table):\n",
    "            return (self._table[j]._key, self._table[j]._value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_lt(self, k):\n",
    "        \"\"\"\n",
    "        Return (key, value) pair with greatest key strictly less than k.\n",
    "        \"\"\"\n",
    "        # j's key >= k\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j > 0:\n",
    "            # note use of j-1\n",
    "            return (self._table[j - 1]._key, self._table[j - 1]._value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_gt(self, k):\n",
    "        \"\"\"\n",
    "        Return (key, value) pair with least key strictly greater than k.\n",
    "        \"\"\"\n",
    "        # j's key >= k\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j < len(self._table) and self._table[j]._key == k:\n",
    "            # advanced past match\n",
    "            j += 1\n",
    "        if j < len(self._table):\n",
    "            return (self._table[j]._key, self._table[j]._value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_range(self, start, stop):\n",
    "        \"\"\"\n",
    "        Iterate all (key, value) pairs such that start <= key <= stop.\n",
    "        If start is None, iteration begins with minimum key of map.\n",
    "        If stop is None, iteration continues through the maximum key of map.\n",
    "        \"\"\"\n",
    "        if start is None:\n",
    "            j = 0\n",
    "        else:\n",
    "            # find first result\n",
    "            j = self._find_index(start, 0, len(self._table) - 1)\n",
    "        while j < len(self._table) and (stop is None or self._table[j]._key < stop):\n",
    "            yield (self._table[j]._key, self._table[j]._value)\n",
    "            j += 1\n",
    "\n",
    "# so the code that is given to is is the recursive approach to finding the index\n",
    "\n",
    "# In the original version of the _find_index method, when the key at mid is less than\n",
    "#  k, it returns mid + 1. This means it effectively skips the key at the mid index and\n",
    "#  continues the search in the upper half of the range. This behavior ensures that if\n",
    "#  there are duplicate keys in the SortedTableMap, it always returns the index of the \n",
    "# first occurrence of the key.\n",
    "\n",
    "# In contrast, the provided variant of _find_index recursively calls itself with a new \n",
    "# range that includes both the upper and lower halves when the key at mid is less than k.\n",
    "#  This means that it might not return the index of the first occurrence of k but rather\n",
    "#  the index of the last occurrence of k.\n",
    "\n",
    "# To illustrate, consider a SortedTableMap with the following keys in sorted order:\n",
    "\n",
    "test = [1, 2, 2, 3, 4, 5]\n",
    "# If you use the original _find_index method to find the index of key 2, it\n",
    "#  will correctly return the index 1 (the first occurrence). However, the\n",
    "#  provided variant will return the index 2 (the last occurrence) because \n",
    "# it continues searching in the upper half of the range when it \n",
    "# encounters a key less than k.\n",
    "\n",
    "# So, the two versions do not always produce the same result, and the\n",
    "#  behavior of the provided variant may not align with the expected behavior \n",
    "# for finding the index of the first occurrence of a key in a SortedTableMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.22 \n",
    "\n",
    "# What is the expected running time of the methods for maintaining a maxima\n",
    "#  set if we insert n pairs such that each pair has lower cost and performance\n",
    "#  than one before it? \n",
    "# \n",
    "# What is contained in the sorted map at the end of this series of operations? \n",
    "# \n",
    "# What if each pair had a lower cost and higher performance than the one before it?\n",
    "\n",
    "# what is a maxima set?\n",
    "\n",
    "# Life is full of trade-offs. We often have to trade off a desired performance measure\n",
    "# against a corresponding cost. Suppose, for the sake of an example, we are interested\n",
    "# in maintaining a database rating automobiles by their maximum speeds and their\n",
    "# cost. We would like to allow someone with a certain amount of money to query our\n",
    "# database to find the fastest car they can possibly afford.\n",
    "\n",
    "# We can model such a trade-off problem as this by using a key-value pair to\n",
    "# model the two parameters that we are trading off, which in this case would be the\n",
    "# pair (cost, speed) for each car.\n",
    "\n",
    "# here is an example.\n",
    "\n",
    "# the pairs that we will insert are: (100, 10) - (92 - 9) - (91 - 8) - (73 - 7)\n",
    "\n",
    "# Unfortunately, if we implement this problem with using the SortedTableMap, the add behavior\n",
    "# has O(n) worst-case running time.\n",
    "\n",
    "# the result would be o(n^2) because for each pair we need to check the tradeoff and \n",
    "# insert the pair to a specific location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# FOR question R10-23\n",
    "\n",
    "![a skip list](img/fig1010.png)\n",
    "\n",
    "First Figure of A Skip List\n",
    "\n",
    "---\n",
    "\n",
    "![flags](img/fig1012.png)\n",
    "\n",
    "Insertion in a Skip List\n",
    "\n",
    "---\n",
    "\n",
    "![deletion](img/fig1013.png)\n",
    "\n",
    "Deletion in a Skip List\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.23 \n",
    "# Draw an example skip list S that results from performing the following\n",
    "# series of operations on the skip list shown in Figure 10.13: \n",
    "# del S[38], S[48] = x , S[24] = y , del S[55]. \n",
    "# \n",
    "# Record your coin flips, as well.\n",
    "\n",
    "\"\"\"First of all, what are Skip Lists?\"\"\"\n",
    "\n",
    "# In Section 10.3.1, we saw that a sorted array will allow O(log n)-time searches via the\n",
    "# binary search algorithm. Unfortunately, update operations on a sorted array have\n",
    "# O(n) worst-case running time because of the need to shift elements. In Chapter 7\n",
    "# we demonstrated that linked lists support very efficient update operations, as long\n",
    "# as the position within the list is identified. \n",
    "# \n",
    "# Unfortunately, we cannot perform fast\n",
    "# searches on a standard linked list; for example, the binary search algorithm requires\n",
    "# an efficient means for direct accessing an element of a sequence by index.\n",
    "# \n",
    "# Skip lists provide a clever compromise to efficiently support search and update\n",
    "# operations. A skip list S for a map M consists of a series of lists {S0, S1 , . . . , Sh}.\n",
    "# Each list Si stores a subset of the items of M sorted by increasing keys, plus items\n",
    "# with two sentinel keys denoted −∞and +∞, where −∞is smaller than every\n",
    "# possible key that can be inserted in M and +∞is larger than every possible key\n",
    "# that can be inserted in M. In addition, the lists in S satisfy the following:\n",
    "\n",
    "# •List S0 contains every item of the map M (plus sentinels −∞and +∞).\n",
    "\n",
    "# •For i = 1, . . . , h−1, list Si contains (in addition to −∞and +∞) a randomly\n",
    "# generated subset of the items in list Si−1.\n",
    "\n",
    "# •List Sh contains only −∞and +∞.\n",
    "\n",
    "# An example of a skip list is shown in Figure 10.10. It is customary to visualize a\n",
    "# skip list S with list S0 at the bottom and lists S1, . . . , Sh above it. Also, we refer to h\n",
    "# as the height of skip list S.\n",
    "\n",
    "# Intuitively, the lists are set up so that Si+1 contains more or less alternate items\n",
    "# of Si. As we shall see in the details of the insertion method, the items in Si+1 are\n",
    "# chosen at random from the items in Si by picking each item from Si to also be in\n",
    "# Si+1 with probability 1/2. \n",
    "# \n",
    "# That is, in essence, we “flip a coin” for each item in S\n",
    "# and place that item in Si+1 if the coin comes up “heads.” Thus, we expect S1 to have\n",
    "# 1about n/2 items, S2 to have about n/4 items, and, in general, Si to have about n/2i\n",
    "# 1items. In other words, we expect the height h of S to be about log n. \n",
    "\n",
    "# back to the question\n",
    "\n",
    "# Creating a skip list example with the given elements and performing the requested operations\n",
    "#  while recording coin flips:\n",
    "\n",
    "# Initial skip list after operations on Fig10.13:\n",
    "\n",
    "# Head -> 12 -> 17 -> 20 -> 31 -> 38 -> 39 -> 42 -> 44 -> 50 -> 55 -> Tail\n",
    "\n",
    "# Now, let's perform the given operations:\n",
    "\n",
    "# Delete S[38]:\n",
    "# Coin Flips: HTTTTTTTTT\n",
    "# After deleting 38:\n",
    "# Head -> 12 -> 17 -> 20 -> 31 -> 39 -> 42 -> 44 -> 50 -> 55 -> Tail\n",
    "\n",
    "# Set S[48] = x:\n",
    "# Coin Flips: HHTT\n",
    "# Since 48 is not in the original skip list, we insert it as follows:\n",
    "# Head -> 12 -> 17 -> 20 -> 31 -> 39 -> 42 -> 44 -> 48(x) -> 50 -> 55 -> Tail\n",
    "\n",
    "# Set S[24] = y:\n",
    "# Coin Flips: HHTT\n",
    "# Since 24 is not in the original skip list, we insert it as follows:\n",
    "# Head -> 12 -> 17 -> 20 -> 24(y) -> 31 -> 39 -> 42 -> 44 -> 48(x) -> 50 -> 55 -> Tail\n",
    "\n",
    "# Delete S[55]:\n",
    "# Coin Flips: HHTT\n",
    "# After deleting 55:\n",
    "# Head -> 12 -> 17 -> 20 -> 24(y) -> 31 -> 39 -> 42 -> 44 -> 48(x) -> 50 -> Tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-10.24 \n",
    "# Give a pseudo-code description of the delitem map operation when\n",
    "# using a skip list.\n",
    "\n",
    "# Procedure __delitem__(k):\n",
    "# Input: A key k to delete from the skip list\n",
    "# Output: None (key k is removed from the skip list)\n",
    "# \n",
    "# 1. Let current be the top-left sentinel node of the skip list.\n",
    "# \n",
    "# 2. Repeat until we reach the bottom level:\n",
    "#    a. While the key of the next node is less than k, move current to the right.\n",
    "#    b. If the key of the next node equals k, delete the node:\n",
    "#       i. Remove the node's reference(s) at the current level(s).\n",
    "#       ii. Move current to the right at the current level.\n",
    "# \n",
    "# 3. If key k was found and deleted, repeat the process starting from the next \n",
    "# level (above the current level) until reaching the top level.\n",
    "# \n",
    "# 4. Return, as key k has been successfully removed from the skip list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# R-10.25 \n",
    "# Give a concrete implementation of the pop method, in the context of a\n",
    "# MutableSet abstract base class, that relies only on the five core set \n",
    "# behaviors described in Section 10.5.2.\n",
    "\n",
    "\"\"\"Before we get to that, here are some definitions\"\"\"\n",
    "\n",
    "# •A set is an unordered collection of elements, without duplicates, that typically\n",
    "#  supports efficient membership tests. In essence, elements of a set are\n",
    "# like keys of a map, but without any auxiliary values.\n",
    "# \n",
    "# •A multiset (also known as a bag) is a set-like container that allows duplicates.\n",
    "# \n",
    "# •A multimap is similar to a traditional map, in that it associates values with\n",
    "# keys; however, in a multimap the same key can be mapped to multiple values.\n",
    "#  For example, the index of this book maps a given term to one or more\n",
    "# locations at which the term occurs elsewhere in the book.\n",
    "\n",
    "\"\"\"Back to the question\"\"\"\n",
    "\n",
    "# FRom book\n",
    "\n",
    "# To aid in the creation of user-defined set classes, Python’s collections module provides\n",
    "#  a MutableSet abstract base class (just as it provides the MutableMapping abstract\n",
    "#  base class discussed in Section 10.1.3). The MutableSet base class provides\n",
    "# concrete implementations for all methods described in Section 10.5.1, except for\n",
    "# five core behaviors (add, discard, __contains__ , __len__ , and __iter__ ) that must\n",
    "# be implemented by any concrete subclass.\n",
    "\n",
    "from collections.abc import MutableSet\n",
    "\n",
    "class MySet(MutableSet):\n",
    "    def __init__(self):\n",
    "        self.elements = set()\n",
    "\n",
    "    def add(self, elem):\n",
    "        self.elements.add(elem)\n",
    "\n",
    "    def discard(self, elem):\n",
    "        self.elements.discard(elem)\n",
    "\n",
    "    def __contains__(self, elem):\n",
    "        return elem in self.elements\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.elements)\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"We can only use the 5 methods we have.\"\"\"\n",
    "        if not self.elements:\n",
    "            raise KeyError(\"pop from an empty set\")\n",
    "        elem_to_pop = next(iter(self.elements))  # Get an arbitrary element\n",
    "        # set methods for insertion and deletion are - add and remove\n",
    "        self.elements.remove(elem_to_pop)\n",
    "        return elem_to_pop\n",
    "\n",
    "# Example usage:\n",
    "s = MySet()\n",
    "s.add(1)\n",
    "s.add(2)\n",
    "s.add(3)\n",
    "\n",
    "print(s.pop())  # This will remove and return an arbitrary element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be True: True\n",
      "This should be False: False\n"
     ]
    }
   ],
   "source": [
    "# R-10.26 \n",
    "# Give a concrete implementation of the isdisjoint method in the context\n",
    "# of the MutableSet abstract base class, relying only on the five primary\n",
    "# abstract methods of that class. Your algorithm should run in O(min(n, m))\n",
    "# where n and m denote the respective cardinalities of the two sets.\n",
    "\n",
    "from collections.abc import MutableSet\n",
    "\n",
    "class MySet(MutableSet):\n",
    "    def __init__(self):\n",
    "        self.elements = set()\n",
    "\n",
    "    def add(self, elem):\n",
    "        self.elements.add(elem)\n",
    "\n",
    "    def discard(self, elem):\n",
    "        self.elements.discard(elem)\n",
    "\n",
    "    def __contains__(self, elem):\n",
    "        return elem in self.elements\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.elements)\n",
    "\n",
    "    def isdisjoint(self, other):\n",
    "        \"\"\"Return True if the two sets are disjoint\"\"\"\n",
    "        if type(other) != MySet:\n",
    "            raise TypeError(\"Cannot make jointness decisions between these objects\")\n",
    "        # find the big set and the small one.\n",
    "        if len(self) < len(other):\n",
    "            for elem in self:\n",
    "                if elem in other:\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            for elem in other:\n",
    "                if elem in self:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "set1 = MySet()\n",
    "\n",
    "set1.add(1)\n",
    "set1.add(2)\n",
    "set1.add(3)\n",
    "\n",
    "set2 = MySet()\n",
    "\n",
    "set2.add(4)\n",
    "set2.add(5)\n",
    "\n",
    "print(f\"This should be True: {set1.isdisjoint(set2)}\")\n",
    "\n",
    "set2.add(1)\n",
    "print(f\"This should be False: {set1.isdisjoint(set2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Important. Skip List Basics.\"\"\"\n",
    "\n",
    "# R-10.27 \n",
    "# What abstraction would you use to manage a database of friends’ birth-\n",
    "# days in order to support efficient queries such as “find all friends whose\n",
    "# birthday is today” and “find the friend who will be the next to celebrate a\n",
    "# birthday”?\n",
    "\n",
    "\"\"\"Answer\"\"\"\n",
    "\n",
    "# Skip lists can be a good choice for managing a database of friends' birthdays when you\n",
    "#  need to support efficient queries such as \"find all friends whose birthday is today\" and\n",
    "#  \"find the friend who will be the next to celebrate a birthday.\" Here's why skip lists\n",
    "#  are a suitable data structure for this scenario:\n",
    "\n",
    "# Efficient Searching: Skip lists are designed to provide efficient searching for elements. \n",
    "# They allow for logarithmic time complexity for search operations, making it quick to find \n",
    "# friends with specific birthdates.\n",
    "\n",
    "# Ordered Data: Skip lists maintain data in a sorted order. Since birthdays are typically\n",
    "#  sorted chronologically, this data structure naturally fits the requirements of this problem.\n",
    "\n",
    "# Balanced Structure: Skip lists maintain a balanced structure, which ensures that operations\n",
    "#  like searching for a friend's birthday or finding the next birthday celebration are \n",
    "# consistently efficient, even as the database grows.\n",
    "\n",
    "# Insertions and Deletions: Skip lists also support efficient insertions and deletions.\n",
    "#  If you need to add new friends to the database or remove friends, these operations can \n",
    "# be performed with logarithmic time complexity.\n",
    "\n",
    "# Queries with Ranges: Skip lists can easily be adapted to handle more complex queries, such\n",
    "#  as finding friends with birthdays in a specific date range. This is valuable if you want \n",
    "# to extend the functionality of your database.\n",
    "\n",
    "# Easy to Implement: While skip lists are not as widely known as some other data structures\n",
    "#  like binary search trees, they are relatively straightforward to implement compared to \n",
    "# more complex structures like balanced BSTs.\n",
    "\n",
    "# Here's a high-level overview of how skip lists work:\n",
    "\n",
    "# Skip lists consist of multiple layers or levels, with each level containing a sorted subset \n",
    "# of the elements from the lower level.\n",
    "\n",
    "# At the top level, you have a sparse representation of the data, with only a few elements. \n",
    "# As you move down the levels, you have increasingly more elements.\n",
    "\n",
    "# Each level allows for faster navigation through the list, effectively \"skipping\" over \n",
    "# large portions of the data, hence the name \"skip list.\"\n",
    "\n",
    "# When you want to find a specific birthday or perform a range query, you can start at the \n",
    "# top level and move down, reducing the search space at each level until you find the \n",
    "# desired element(s) or range.\n",
    "\n",
    "# In summary, skip lists strike a good balance between simplicity of implementation and\n",
    "#  efficient querying, making them a suitable choice for managing a database of \n",
    "# friends' birthdays, especially when you need to support various queries efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.28 \n",
    "# On page 406 of Section 10.1.3, we give an implementation of the method\n",
    "# setdefault as it might appear in the MutableMapping abstract base class.\n",
    "# While that method accomplishes the goal in a general fashion, its efficiency is less\n",
    "#  than ideal. \n",
    "\n",
    "# here is the method\n",
    "def setdefault(self, k ,d):\n",
    "    try:\n",
    "        return self[k]\n",
    "    except KeyError:\n",
    "        self[k] = d\n",
    "        return d\n",
    "\n",
    "# In particular, when the key is new, there will be\n",
    "# a failed search due to the initial use of __getitem__ , and then a subsequent\n",
    "#  insertion via __setitem__ . \n",
    "# \n",
    "# For a concrete implementation, such as the UnsortedTableMap, this is twice the\n",
    "#  work because a complete scan of the table will take place during the failed __getitem__\n",
    "#  , and  then another complete scan of the table takes place due to the implementation of\n",
    "# __setitem__. \n",
    "# \n",
    "# A better solution is for the UnsortedTableMap class to override setdefault to\n",
    "#  provide a direct solution that performs a single search.\n",
    "\n",
    "# Give such an implementation of UnsortedTableMap.setdefault.\n",
    "\n",
    "\"\"\"Answer\"\"\"\n",
    "\n",
    "# To improve the efficiency of the setdefault method in the UnsortedTableMap class, we can\n",
    "#  override it to directly search for the key and perform the insertion if the key is not\n",
    "#  found, eliminating the need for two separate searches. Here's an implementation of \n",
    "# setdefault for UnsortedTableMap:\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class UnsortedTableMap(MutableMapping):\n",
    "    def __init__(self):\n",
    "        self._table = []\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        for key, value in self._table:\n",
    "            if key == k:\n",
    "                return value\n",
    "        raise KeyError(f'Key not found: {k}')\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        for i, (key, value) in enumerate(self._table):\n",
    "            if key == k:\n",
    "                self._table[i] = (k, v)\n",
    "                return\n",
    "        self._table.append((k, v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        for i, (key, value) in enumerate(self._table):\n",
    "            if key == k:\n",
    "                del self._table[i]\n",
    "                return\n",
    "        raise KeyError(f'Key not found: {k}')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for key, value in self._table:\n",
    "            yield key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._table)\n",
    "\n",
    "    def setdefault(self, k, d):\n",
    "        for key, value in self._table:\n",
    "            if key == k:\n",
    "                return value\n",
    "        self._table.append((k, d))\n",
    "        return d\n",
    "\n",
    "# In this implementation of setdefault, we iterate through the _table list to\n",
    "#  search for the key k. If we find it, we return the associated value. If the\n",
    "#  key is not found, we directly append a new key-value pair to the _table list\n",
    "#  and return the default value d. This approach avoids the need for two separate\n",
    "#  searches, making it more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C-10.29 \n",
    "# Repeat Exercise C-10.28 for the ProbeHashMap class\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "from random import randrange\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object() # sentinel object that marks locations of previous deletions\n",
    "\n",
    "    def _is_avaliable(self, j):\n",
    "        \"\"\"Return True if index j is avaliable in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "\n",
    "    def _find_slot(self, j ,k):\n",
    "        r\"\"\"\n",
    "        Search for key k in bucket at index j.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_avaliable(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j                          # mark this as first avail\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail)              # search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)                            # found a match\n",
    "            j = (j + 1) % len(self._table)                  # keep looking (cyclically)\n",
    "\n",
    "    def bucket_getitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        return self._table[s]._value\n",
    "\n",
    "    def bucket_setitem(self, j, k, v): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v)                # insert new item\n",
    "            self._n += 1                                    # size has increased\n",
    "        else:\n",
    "            self._table[s]._value = v                       # overwrite existing\n",
    "\n",
    "    def bucket_delitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL                # mark as vacated\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self. table)):                   # scan entire table\n",
    "            if not self._is_avaliable(j):\n",
    "                yield self._table[j]._key\n",
    "\n",
    "    def setdefault(self, k, d):\n",
    "        j = self._hash_function(k)  # Compute the initial bucket index\n",
    "        found, s = self._find_slot(j, k)  # Attempt to find the key in the bucket\n",
    "\n",
    "        if found:\n",
    "            return self._table[s]._value  # If found, return the existing value\n",
    "\n",
    "        # Key not found, insert the new key-value pair\n",
    "        self._table[s] = self._Item(k, d)\n",
    "        self._n += 1\n",
    "\n",
    "        if self._n > len(self._table) // 2:\n",
    "            self._resize(2 * len(self._table) - 1)\n",
    "\n",
    "        return d  # Return the default value, as it has been inserted\n",
    "\n",
    "phm = ProbeHashMap()\n",
    "\n",
    "phm.bucket_setitem(0 , \"a\", 1)\n",
    "phm.bucket_setitem(1 , \"b\", 2)\n",
    "phm.bucket_setitem(2 , \"c\", 3)\n",
    "\n",
    "phm.bucket_getitem(1, \"b\")\n",
    "\n",
    "\"\"\"In this setdefault implementation:\"\"\"\n",
    "\n",
    "# - We first calculate the initial bucket index (j) using the hash function.\n",
    "# - Then, we attempt to find the key in the bucket using the _find_slot method.\n",
    "# - If the key is found (found is True), we return the existing value associated with the key.\n",
    "# - If the key is not found, we insert the new key-value pair into the table.\n",
    "# - If the load factor exceeds 0.5, we resize the table to maintain efficiency.\n",
    "# - Finally, we return the default value d, whether it's newly inserted or already existed.\n",
    "\n",
    "# This implementation ensures that the setdefault method efficiently finds and \n",
    "# inserts key-value pairs in the ProbeHashMap without unnecessary searches or insertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.30 \n",
    "# Repeat Exercise C-10.28 for the ChainHashMap class.\n",
    "\n",
    "# Here is ChainHashMap\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "from random import randrange\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        return bucket[k]  # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()  # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:  # key was new to the table\n",
    "            self._n += 1  # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        del bucket[k]  # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:  # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "    # HERE IS THE ADDED SET DEFAULT METHOD\n",
    "    def setdefault(self, k, d):\n",
    "        j = self._hash_function(k)  # Compute the initial bucket index\n",
    "        bucket = self._table[j]  # Get the bucket at the initial index\n",
    "\n",
    "        if bucket is None:\n",
    "            # If the bucket is empty, Make a new UnsortedTableMap\n",
    "            bucket = UnsortedTableMap()\n",
    "            self._table[j] = bucket\n",
    "\n",
    "        if k not in bucket:\n",
    "            # If the key is not in the bucket, insert the new key-value pair\n",
    "            bucket[k] = d\n",
    "            self._n += 1\n",
    "\n",
    "            if self._n > len(self._table) // 2:\n",
    "                self._resize(2 * len(self._table) - 1)  # Resize if load factor exceeds 0.5\n",
    "\n",
    "        return bucket.get(k, d)  # Return the value associated with the key   \n",
    "\n",
    "\n",
    "# In this setdefault implementation:\n",
    "\n",
    "# - We first calculate the initial bucket index (j) using the hash function.\n",
    "# - Then, we retrieve the bucket at the initial index.\n",
    "# - If the bucket is empty (i.e., None), we Make a new UnsortedTableMap to use as the bucket.\n",
    "# - We check if the key is in the bucket. If not, we insert the new key-value pair into the bucket.\n",
    "# - If the load factor exceeds 0.5, we resize the table to maintain efficiency.\n",
    "# - Finally, we return the value associated with the key, either the existing one or the\n",
    "#  default value d if it's a new insertion.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first prime number in the range [10, 20] is 11.\n"
     ]
    }
   ],
   "source": [
    "# C-10.31 \n",
    "# For an ideal compression function, the capacity of the bucket array for a\n",
    "# hash table should be a prime number. Therefore, we consider the problem\n",
    "# of locating a prime number in a range [M, 2M]. \n",
    "# \n",
    "# Implement a method for finding such a prime by using the sieve algorithm. \n",
    "# \n",
    "# In this algorithm, we allocate a 2M cell Boolean array A, such that cell i is\n",
    "#  associated with the integer i. We then initialize the array cells to\n",
    "#  all be “true” and we “mark off” all the cells that are multiples \n",
    "# of 2, 3, 5, 7, and so on. \n",
    "# \n",
    "# This process  can stop after it reaches a number larger than √2M. (Hint: Consider a\n",
    "# bootstrapping method for finding the primes up to √2M.\n",
    "\n",
    "import math\n",
    "\n",
    "def primes(size):\n",
    "    seq = [True] * size\n",
    "    seq[0] = seq[1] = False  # 0 and 1 are not prime\n",
    "\n",
    "    for index in range(2, int(math.sqrt(size)) + 1):\n",
    "        if seq[index]:\n",
    "            # Mark multiples of index as non-prime\n",
    "            for multiple in range(index * index, size, index):\n",
    "                seq[multiple] = False\n",
    "\n",
    "    return seq\n",
    "\n",
    "def is_prime(x):\n",
    "    \"\"\"Return True if the given integer number is prime\"\"\"\n",
    "    if x < 2:\n",
    "        return False\n",
    "    for elem in range(2, int(math.sqrt(x)) + 1):\n",
    "        if x % elem == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "M = 10\n",
    "size = 2 * M  # Replace M with your desired value\n",
    "prime_flags = primes(size)\n",
    "\n",
    "# Find the first prime in the range [M, 2M]\n",
    "for i in range(M, 2 * M + 1):\n",
    "    if prime_flags[i]:\n",
    "        print(f\"The first prime number in the range [{M}, {2 * M}] is {i}.\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"No prime number found in the range [{M}, {2 * M}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.32 \n",
    "# Perform experiments on our ChainHashMap and ProbeHashMap classes\n",
    "# to measure its efficiency using random key sets and varying limits on the\n",
    "# load factor (see Exercise R-10.15)\n",
    "\n",
    "# To perform experiments on the ChainHashMap and ProbeHashMap classes to measure\n",
    "#  their efficiency with varying load factors, you can follow these steps:\n",
    "\n",
    "# Make test cases with random key sets.\n",
    "\n",
    "# Insert keys and values into both ChainHashMap and ProbeHashMap instances with different load factors.\n",
    "\n",
    "# Measure the time taken for insertion, retrieval, and deletion operations.\n",
    "\n",
    "# Analyze the results to see how performance varies with different load factors.\n",
    "\n",
    "\n",
    "from random import randrange\n",
    "import random\n",
    "import time\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class UnsortedTableMap(MutableMapping):\n",
    "    def __init__(self):\n",
    "        self._table = []\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        for key, value in self._table:\n",
    "            if key == k:\n",
    "                return value\n",
    "        raise KeyError(f'Key not found: {k}')\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        for i, (key, value) in enumerate(self._table):\n",
    "            if key == k:\n",
    "                self._table[i] = (k, v)\n",
    "                return\n",
    "        self._table.append((k, v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        for i, (key, value) in enumerate(self._table):\n",
    "            if key == k:\n",
    "                del self._table[i]\n",
    "                return\n",
    "        raise KeyError(f'Key not found: {k}')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for key, value in self._table:\n",
    "            yield key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._table)\n",
    "\n",
    "    def setdefault(self, k, d):\n",
    "        for key, value in self._table:\n",
    "            if key == k:\n",
    "                return value\n",
    "        self._table.append((k, d))\n",
    "        return d\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object() # sentinel object that marks locations of previous deletions\n",
    "\n",
    "    def _is_avaliable(self, j):\n",
    "        \"\"\"Return True if index j is avaliable in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "\n",
    "    def _find_slot(self, j ,k):\n",
    "        r\"\"\"\n",
    "        Search for key k in bucket at index j.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_avaliable(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j                          # mark this as first avail\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail)              # search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)                            # found a match\n",
    "            j = (j + 1) % len(self._table)                  # keep looking (cyclically)\n",
    "\n",
    "    def bucket_getitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        return self._table[s]._value\n",
    "\n",
    "    def bucket_setitem(self, j, k, v): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v)                # insert new item\n",
    "            self._n += 1                                    # size has increased\n",
    "        else:\n",
    "            self._table[s]._value = v                       # overwrite existing\n",
    "\n",
    "    def bucket_delitem(self, j, k): \n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError( \"Key Error:\" + repr(k))         # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL                # mark as vacated\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self. table)):                   # scan entire table\n",
    "            if not self._is_avaliable(j):\n",
    "                yield self._table[j]._key\n",
    "\n",
    "    def setdefault(self, k, d):\n",
    "        j = self._hash_function(k)  # Compute the initial bucket index\n",
    "        found, s = self._find_slot(j, k)  # Attempt to find the key in the bucket\n",
    "\n",
    "        if found:\n",
    "            return self._table[s]._value  # If found, return the existing value\n",
    "\n",
    "        # Key not found, insert the new key-value pair\n",
    "        self._table[s] = self._Item(k, d)\n",
    "        self._n += 1\n",
    "\n",
    "        if self._n > len(self._table) // 2:\n",
    "            self._resize(2 * len(self._table) - 1)\n",
    "\n",
    "        return d  # Return the default value, as it has been inserted\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        return bucket[k]  # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()  # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:  # key was new to the table\n",
    "            self._n += 1  # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        del bucket[k]  # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:  # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "    # HERE IS THE ADDED SET DEFAULT METHOD\n",
    "    def setdefault(self, k, d):\n",
    "        j = self._hash_function(k)  # Compute the initial bucket index\n",
    "        bucket = self._table[j]  # Get the bucket at the initial index\n",
    "\n",
    "        if bucket is None:\n",
    "            # If the bucket is empty, Make a new UnsortedTableMap\n",
    "            bucket = UnsortedTableMap()\n",
    "            self._table[j] = bucket\n",
    "\n",
    "        if k not in bucket:\n",
    "            # If the key is not in the bucket, insert the new key-value pair\n",
    "            bucket[k] = d\n",
    "            self._n += 1\n",
    "\n",
    "            if self._n > len(self._table) // 2:\n",
    "                self._resize(2 * len(self._table) - 1)  # Resize if load factor exceeds 0.5\n",
    "\n",
    "        return bucket.get(k, d)  # Return the value associated with the key   \n",
    "\n",
    "# Function to generate a random key set\n",
    "def generate_random_key_set(size):\n",
    "    return [random.randint(1, 10000) for _ in range(size)]\n",
    "\n",
    "# Function to measure the performance of a hash map\n",
    "def measure_performance(hash_map, keys, load_factor):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Insert keys and values\n",
    "    for key in keys:\n",
    "        hash_map[key] = key\n",
    "\n",
    "    insertion_time = time.time() - start_time\n",
    "\n",
    "    # Measure retrieval time\n",
    "    start_time = time.time()\n",
    "    for key in keys:\n",
    "        _ = hash_map[key]\n",
    "\n",
    "    retrieval_time = time.time() - start_time\n",
    "\n",
    "    # Measure deletion time\n",
    "    start_time = time.time()\n",
    "    for key in keys:\n",
    "        del hash_map[key]\n",
    "\n",
    "    deletion_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"Load Factor\": load_factor,\n",
    "        \"Insertion Time\": insertion_time,\n",
    "        \"Retrieval Time\": retrieval_time,\n",
    "        \"Deletion Time\": deletion_time,\n",
    "    }\n",
    "\n",
    "# Main experiment loop\n",
    "load_factors = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "key_set_size = 1000  # Adjust as needed\n",
    "num_experiments = 1  # Number of experiments per load factor\n",
    "\n",
    "for load_factor in load_factors:\n",
    "    print(f\"Load Factor: {load_factor}\")\n",
    "    for _ in range(num_experiments):\n",
    "        keys = generate_random_key_set(int(key_set_size * load_factor))\n",
    "\n",
    "        # Test ChainHashMap\n",
    "        chain_map = ChainHashMap()\n",
    "        chain_results = measure_performance(chain_map, keys, load_factor)\n",
    "\n",
    "        # Test ProbeHashMap\n",
    "        probe_map = ProbeHashMap()\n",
    "        probe_results = measure_performance(probe_map, keys, load_factor)\n",
    "\n",
    "        print(f\"ChainHashMap: {chain_results}\")\n",
    "        print(f\"ProbeHashMap: {probe_results}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.33 \n",
    "# Our implementation of separate chaining in ChainHashMap conserves\n",
    "# memory by representing empty buckets in the table as None, rather than\n",
    "# as empty instances of a secondary structure. Because many of these \n",
    "# buckets will hold a single item, a better optimization is to have those slots of\n",
    "# the table directly reference the Item instance, and to reserve use of secondary\n",
    "#  containers for buckets that have two or more items. Modify our\n",
    "# implementation to provide this additional optimization.\n",
    "\n",
    "# Original Code\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        return bucket[k]  # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()  # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:  # key was new to the table\n",
    "            self._n += 1  # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "        del bucket[k]  # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:  # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "    # HERE IS THE ADDED SET DEFAULT METHOD\n",
    "    def setdefault(self, k, d):\n",
    "        j = self._hash_function(k)  # Compute the initial bucket index\n",
    "        bucket = self._table[j]  # Get the bucket at the initial index\n",
    "\n",
    "        if bucket is None:\n",
    "            # If the bucket is empty, Make a new UnsortedTableMap\n",
    "            bucket = UnsortedTableMap()\n",
    "            self._table[j] = bucket\n",
    "\n",
    "        if k not in bucket:\n",
    "            # If the key is not in the bucket, insert the new key-value pair\n",
    "            bucket[k] = d\n",
    "            self._n += 1\n",
    "\n",
    "            if self._n > len(self._table) // 2:\n",
    "                self._resize(2 * len(self._table) - 1)  # Resize if load factor exceeds 0.5\n",
    "\n",
    "        return bucket.get(k, d)  # Return the value associated with the key   \n",
    "\n",
    "\"\"\"Answer\"\"\"\n",
    "\n",
    "# To optimize the ChainHashMap implementation by directly referencing the Item instances \n",
    "# in slots that hold a single item and reserving secondary containers for buckets with\n",
    "#  two or more items, you can make the following changes to the ChainHashMap class:\n",
    "# \n",
    "# Make a new _Item class that stores a key-value pair.\n",
    "# \n",
    "# Modify the _Item class to include a reference to the next item in the chain (a singly\n",
    "#  linked list). This reference will be None for the last item in the chain.\n",
    "# \n",
    "# Update the _Item class to include a count of the number of items in the chain. You can\n",
    "#  increment this count each time you add an item to the chain.\n",
    "# \n",
    "# Update the _bucket_setitem and _bucket_delitem methods to handle chaining items within \n",
    "# a slot. You will need to check if an item already exists in the slot. If it does, you can\n",
    "#  add the new item to the end of the chain or remove the item from the chain.\n",
    "\n",
    "class ChainHashMap_(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\", \"_next\", \"_count\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "            self._next = None  # Reference to the next item in the chain\n",
    "            self._count = 1    # Count of items in the chain\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        while bucket is not None:\n",
    "            if bucket._key == k:\n",
    "                return bucket._value\n",
    "            bucket = bucket._next\n",
    "        raise KeyError('Key Error: ' + repr(k))  # no match found\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = self._Item(k, v)\n",
    "        else:\n",
    "            bucket = self._table[j]\n",
    "            while bucket:\n",
    "                if bucket._key == k:\n",
    "                    # Key already exists, update the value\n",
    "                    bucket._value = v\n",
    "                    return\n",
    "                prev_bucket = bucket\n",
    "                bucket = bucket._next\n",
    "            # Key not found, add a new item to the chain\n",
    "            prev_bucket._next = self._Item(k, v)\n",
    "            self._table[j]._count += 1  # Increment the count\n",
    "\n",
    "        self._n += 1  # Increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        prev_bucket = None\n",
    "        while bucket is not None:\n",
    "            if bucket._key == k:\n",
    "                if prev_bucket:\n",
    "                    # Remove the item from the chain\n",
    "                    prev_bucket._next = bucket._next\n",
    "                else:\n",
    "                    # The first item in the chain is removed\n",
    "                    self._table[j] = bucket._next\n",
    "                self._table[j]._count -= 1  # Decrement the count\n",
    "                if self._table[j]._count == 1:\n",
    "                    # If only one item left in the chain, remove the chain\n",
    "                    self._table[j] = self._table[j]._next\n",
    "                self._n -= 1  # Decrease overall map size\n",
    "                return\n",
    "            prev_bucket = bucket\n",
    "            bucket = bucket._next\n",
    "        raise KeyError('Key Error: ' + repr(k))  # no match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Genius - Real Insight\"\"\"\n",
    "\n",
    "# C-10.34 \n",
    "# Computing a hash code can be expensive, especially for lengthy keys.\n",
    "# \n",
    "#  In our hash table implementations, we compute the hash code when first inserting\n",
    "#  an item, and recompute each item’s hash code each time we resize\n",
    "# our table. \n",
    "# \n",
    "# Python’s dict class makes an interesting trade-off. The hash\n",
    "# code is computed once, when an item is inserted, and the hash code is\n",
    "# stored as an extra field of the item composite, so that it need not be recomputed.\n",
    "#\n",
    "#  Reimplement our HashTableBase class to use such an approach.\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class HashTableBase(MutableMapping):\n",
    "    \"\"\"Abstract base class for hash table implementations.\"\"\"\n",
    "\n",
    "    def __init__(self, cap=11):\n",
    "        \"\"\"Make an empty hash table.\"\"\"\n",
    "        self._table = cap * [None]                      # Make an empty table (list)\n",
    "        self._n = 0                                     # Number of entries in the map\n",
    "        self._prime = 109345121                         # Prime number for MAD compression\n",
    "        self._scale = 1 + randrange(self._prime - 1)    # Scale for MAD compression\n",
    "        self._shift = randrange(self._prime)            # Shift for MAD compression\n",
    "        self._hash_codes = {}                           # Dictionary to store hash codes\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of entries in the hash table.\"\"\"\n",
    "        return self._n\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        \"\"\"Compute the hash code for key k.\"\"\"\n",
    "        if k in self._hash_codes:\n",
    "            return self._hash_codes[k]  # Use the stored hash code\n",
    "        hash_code = (hash(k) * self._scale + self._shift) % self._prime % len(self._table)\n",
    "        self._hash_codes[k] = hash_code  # Store the hash code\n",
    "        return hash_code\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return the value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k)\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)\n",
    "        if self._n > len(self._table) // 2:\n",
    "            self._resize(2 * len(self._table) - 1)\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove the item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)\n",
    "        self._n -= 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate an iterator of keys in the hash table.\"\"\"\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "# With this implementation, the hash code for each key is computed only once and stored\n",
    "#  in the _hash_codes dictionary. Subsequent operations that require the hash code can \n",
    "# retrieve it from this dictionary, avoiding the need to recompute it. This optimization can\n",
    "#  reduce the overhead of computing hash codes, especially for lengthy keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.35 \n",
    "# Describe how to perform a removal from a hash table that uses linear\n",
    "# probing to resolve collisions where we do not use a special marker to\n",
    "# represent deleted elements. That is, we must rearrange the contents so that\n",
    "# it appears that the removed entry was never inserted in the first place.\n",
    "\n",
    "# When removing an entry from a hash table that uses linear probing to resolve\n",
    "#  collisions without using a special marker for deleted elements, you need to \n",
    "# ensure that the removed entry does not break the linear probing sequence and \n",
    "# that it appears as if it was never inserted in the first place. Here's a step-by-step\n",
    "#  guide on how to perform such a removal:\n",
    "\n",
    "# Locate the Entry: First, use the hash function to locate the index (slot) where the\n",
    "#  entry you want to remove is stored. If the entry is not found at that index, follow\n",
    "#  the linear probing sequence to search for it.\n",
    "\n",
    "# Mark the Entry as Deleted: Once you find the entry you want to remove, you cannot \n",
    "# simply delete it, as it would break the linear probing sequence. Instead, you should \n",
    "# mark it as deleted, which effectively indicates that the slot is available for new\n",
    "#  insertions but still preserves the sequence.\n",
    "\n",
    "# Adjust the Linear Probing Sequence: After marking the entry as deleted, you need to\n",
    "#  adjust the linear probing sequence to ensure that you can continue searching for \n",
    "# other entries correctly. To do this, you should continue probing linearly from the\n",
    "#  marked slot, looking for the next valid entry in the sequence.\n",
    "\n",
    "# Stop When a Valid Entry Is Found: Continue probing until you either find the next\n",
    "#  valid entry (i.e., an entry that is not deleted) or reach an empty slot (indicating\n",
    "#  the end of the sequence). When a valid entry is found, you can leave it where it is.\n",
    "\n",
    "# Repeat as Necessary: If there are additional entries in the probing sequence, you can\n",
    "#  repeat steps 2 through 4 as needed until you either find all the entries you need or\n",
    "#  reach an empty slot.\n",
    "\n",
    "# Update the Table Size: If the number of marked entries (deleted entries) becomes \n",
    "# significant compared to the total number of slots in the table, you may need to consider\n",
    "#  resizing the table to maintain good performance. Resizing typically involves creating\n",
    "#  a larger table and rehashing the valid entries into the new table while ignoring the\n",
    "#  marked (deleted) entries.\n",
    "\n",
    "# By following these steps, you can perform a removal from a hash table using linear probing\n",
    "#  without the need for a special marker for deleted elements. This approach ensures that\n",
    "#  the linear probing sequence remains intact and that the removed entry does not disrupt\n",
    "#  the table's operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.36 \n",
    "\n",
    "# The quadratic probing strategy has a clustering problem related to the way\n",
    "# it looks for open slots. Namely, when a collision occurs at bucket h(k), it \n",
    "# checks buckets A[(h(k) + i2) mod N], for i = 1, 2, . . . , N −1.\n",
    "#   a. Show that i2 mod N will assume at most (N + 1)/2 distinct values,\n",
    "# for N prime, as i ranges from 1 to N −1. As a part of this \n",
    "# justification, note that i2 mod N = ( N −i)2 mod N for all i.\n",
    "#   b. A better strategy is to choose a prime N such that N mod 4 = 3 and \n",
    "# then to check the buckets A[(h(k) ±i2) mod N] as i ranges from 1\n",
    "# to (N −1)/2, alternating between plus and minus. Show that this\n",
    "# alternate version is guaranteed to check every bucket in A.\n",
    "\n",
    "# a. To show that i^2 mod N will assume at most (N + 1)/2 distinct values for\n",
    "#  N prime, as i ranges from 1 to N - 1, we can use the property \n",
    "# that i^2 mod N = (N - i)^2 mod N for all i. \n",
    "# \n",
    "# Let's consider the values of i^2 mod N for i ranging from 1 to N - 1:\n",
    "# \n",
    "#   - When i = 1, i^2 mod N = 1^2 mod N = 1.\n",
    "#   - When i = 2, i^2 mod N = 2^2 mod N = 4 mod N. But since N is prime, all values\n",
    "#  from 1 to N - 1 are relatively prime to N, and N cannot divide 4. \n",
    "# Therefore, 4 mod N is distinct from 1.\n",
    "#   - When i = 3, i^2 mod N = 3^2 mod N = 9 mod N. Similarly, since N is prime, all \n",
    "# values from 1 to N - 1 are relatively prime to N, and N cannot divide 9. \n",
    "# Therefore, 9 mod N is distinct from both 1 and 4 mod N.\n",
    "#   - This pattern continues, and for each i, i^2 mod N is distinct from the \n",
    "# previously calculated values.\n",
    "\n",
    "# As you can see, i^2 mod N takes on distinct values for each value of i from 1 \n",
    "# to N - 1. Therefore, it assumes at most (N + 1)/2 distinct values.\n",
    "\n",
    "# b. To show that the strategy of choosing a prime N such that N mod 4 = 3 and \n",
    "# checking the buckets A[(h(k) ± i^2) mod N] as i ranges from 1 to (N - 1)/2, alternating\n",
    "#  between plus and minus, guarantees checking every bucket in A, we can consider\n",
    "#  how this approach distributes the probing sequence:\n",
    "# \n",
    "#   - When i = 1, it checks buckets A[(h(k) + 1^2) mod N] and A[(h(k) - 1^2) mod N].\n",
    "#   - When i = 2, it checks buckets A[(h(k) + 2^2) mod N] and A[(h(k) - 2^2) mod N].\n",
    "#   - This pattern continues, with each i, it checks two new buckets, one using the\n",
    "#  plus sign and one using the minus sign, ensuring that all buckets are eventually checked.\n",
    "\n",
    "# Since N is prime, this approach ensures that the probing sequence covers every \n",
    "# bucket in A because the values of i^2 mod N are distinct for each i from 1 \n",
    "# to (N - 1)/2, and alternating between plus and minus ensures that both sides\n",
    "#  of the collision point are explored. This approach helps reduce clustering\n",
    "# issues associated with quadratic probing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.37 \n",
    "# Refactor our ProbeHashMap design so that the sequence of secondary\n",
    "# probes for collision resolution can be more easily customized. Demonstrate\n",
    "#  your new framework by providing separate concrete subclasses for\n",
    "# linear probing and quadratic probing.\n",
    "\n",
    "# To refactor the ProbeHashMap design so that the sequence of secondary probes\n",
    "#  for collision resolution can be more easily customized, we can Make a\n",
    "#  new class called CustomProbeHashMap that allows us to define our own probing \n",
    "# sequence strategy. This new class will provide a framework for defining\n",
    "#  custom probing sequences.\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a non public _Item class\"\"\"\n",
    "\n",
    "    # nested _Item class\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key      # only compare keys\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "             return self._key < other._key      # compare based on keys\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression\"\"\"\n",
    "    def __init__(self, cap = 11, p = 109345121):\n",
    "        \"\"\"Make an empty hash-table map\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                         # Number of entries in the map\n",
    "        self._prime = p                     # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)    # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)          # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self,k):\n",
    "        return (hash(k) *  self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)\n",
    "\n",
    "    def __setitem__(self, k, v) :\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)               # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:         # keep load factor <= 0.5\n",
    "            self._resize(2*len(self._table) - 1)    # number 2^x - 1 often prime\n",
    "\n",
    "    def _resize(self, c):               # resize bucket array to capacity c\n",
    "        old = list(self.items())        # use iteration to record existing items\n",
    "        self._table = c * [None]        # reset the table to desired capacity\n",
    "        self._n = 0                     # n recomputed during subsequent adds\n",
    "        for (k,v) in old:       \n",
    "            self[k] = v                  # reinsert old key value pair\n",
    "\n",
    "    def __delitem__(self, k ):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)       # may Raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "class CustomProbeHashMap(HashMapBase):\n",
    "    def __init__(self, cap=11, p=109345121, probing_sequence=None):\n",
    "        super().__init__(cap, p)\n",
    "        self.probing_sequence = probing_sequence or self.default_probing_sequence\n",
    "\n",
    "    def _get_probe_indices(self, j, k):\n",
    "        for i in self.probing_sequence():\n",
    "            yield (j + i) % len(self._table)\n",
    "\n",
    "    def _find_slot(self, j, k):\n",
    "        firstAvail = None\n",
    "        for i in self._get_probe_indices(j, k):\n",
    "            if self._is_available(i):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = i\n",
    "                if self._table[i] is None:\n",
    "                    return (False, firstAvail)\n",
    "            elif k == self._table[i]._key:\n",
    "                return (True, i)\n",
    "        return (False, firstAvail)\n",
    "\n",
    "    def default_probing_sequence(self):\n",
    "        \"\"\"Default probing sequence (linear probing).\"\"\"\n",
    "        i = 1\n",
    "        while True:\n",
    "            yield i\n",
    "            i += 1\n",
    "\n",
    "    # You can add other custom probing sequences as needed\n",
    "\n",
    "# Example usage:\n",
    "# linear_probing_map = CustomProbeHashMap(probing_sequence=CustomProbeHashMap.default_probing_sequence)\n",
    "# quadratic_probing_map = CustomProbeHashMap(probing_sequence=my_custom_quadratic_sequence)\n",
    "\n",
    "# With this design, you can Make instances of CustomProbeHashMap and specify your\n",
    "#  own probing sequence strategy as a function. The default_probing_sequence method \n",
    "# provides a linear probing sequence by default, but you can define your own custom \n",
    "# probing sequences and pass them as arguments when creating instances of CustomProbeHashMap.\n",
    "#  This allows you to easily customize the collision resolution strategy for the hash map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.38 \n",
    "# Design a variation of binary search for performing the multimap \n",
    "# operation find_all(k) implemented with a sorted search table that includes \n",
    "# duplicates, and show that it runs in time O(s+ log n), where n is the number\n",
    "# of elements in the dictionary and s is the number of items with given key k.\n",
    "\n",
    "# To perform the find_all(k) operation efficiently with a sorted search table \n",
    "# that includes duplicates, you can use a modified binary search algorithm. \n",
    "# Here's a high-level outline of how to achieve this and analyze its time complexity:\n",
    "\n",
    "# Sort the search table by the keys.\n",
    "\n",
    "#       Use binary search to find the first occurrence of key k in the sorted table.\n",
    "#  Let's call this index first_occurrence.\n",
    "\n",
    "#       Use binary search again to find the last occurrence of key k in the sorted table.\n",
    "# Let's call this index last_occurrence.\n",
    "\n",
    "#       All elements with key k are now in the range from first_occurrence to\n",
    "#  last_occurrence in the sorted table.\n",
    "\n",
    "def find_all(self, k):\n",
    "    first_occurrence = self.find_first_occurrence(k)\n",
    "    last_occurrence = self.find_last_occurrence(k)\n",
    "    \n",
    "    if first_occurrence is None or last_occurrence is None:\n",
    "        return []  # Key not found\n",
    "    \n",
    "    # Extract elements with key k from the sorted search table\n",
    "    result = []\n",
    "    for i in range(first_occurrence, last_occurrence + 1):\n",
    "        result.append(self.sorted_table[i])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Now, let's analyze the time complexity:\n",
    "\n",
    "# Sorting the table initially takes O(n * log n) time, where n is the\n",
    "#  number of elements in the dictionary.\n",
    "\n",
    "# Binary search for the first occurrence of key k takes O(log n) time.\n",
    "\n",
    "# Binary search for the last occurrence of key k also takes O(log n) time.\n",
    "\n",
    "# Extracting the elements with key k from the sorted table takes O(s) time, where\n",
    "#  s is the number of items with key k.\n",
    "\n",
    "# Overall, the time complexity of the find_all(k) operation is O(n * log n) \n",
    "# (sorting) + O(log n) (first occurrence) + O(log n) (last occurrence) + O(s)\n",
    "#  (extraction) = O(n * log n) + O(log n) + O(log n) + O(s) = O(n * log n + s).\n",
    "\n",
    "# So, the find_all(k) operation runs in O(s + log n) time, where n is the\n",
    "# number of elements in the dictionary, and s is the number of items with \n",
    "# the given key k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.39 \n",
    "\n",
    "# Although keys in a map are distinct, the binary search algorithm can be\n",
    "# applied in a more general setting in which an array stores possibly duplicative\n",
    "#  elements in nondecreasing order. Consider the goal of identifying the\n",
    "# index of the leftmost element with key greater than or equal to given k.\n",
    "\n",
    "# Does the find index method as given in Code Fragment 10.8 guarantee\n",
    "# such a result? Does the find index method as given in Exercise R-10.21\n",
    "# guarantee such a result? Justify your answers.\n",
    "\n",
    "# code fragment 10.8\n",
    "def _find_index(self, k, low, high):\n",
    "    \"\"\"\n",
    "    Return index of the leftmost item with key greater than or equal to k.\n",
    "    Return high + 1 if no such item qualifies.\n",
    "    That is, j will be returned such that:\n",
    "        all items of slice table[low:j] have key < k\n",
    "        all items of slice table[j:high+1] have key >= k\n",
    "    \"\"\"\n",
    "    if high < low:\n",
    "        # no element qualifies\n",
    "        return high + 1\n",
    "    else:\n",
    "        mid = (low + high) // 2\n",
    "        if k == self._table[mid]._key:\n",
    "            # found exact match\n",
    "            return mid\n",
    "        elif k < self._table[mid]._key:\n",
    "            # note: may return mid\n",
    "            return self._find_index(k, low, mid - 1)\n",
    "        else:\n",
    "            # answer is right of mid\n",
    "            return self._find_index(k, mid + 1, high)\n",
    "\n",
    "# R-10.21 is the recursive without the check for mid directly.\n",
    "\n",
    "def _find_index(self, k, low, high): \n",
    "    \"\"\"In contrast, the provided variant of _find_index recursively calls\n",
    "     itself with a new range that includes both the upper and lower halves\n",
    "      when the key at mid is less than k. This means that it might not\n",
    "       return the index of the first occurrence of k but rather the index\n",
    "    of the last occurrence of k.\"\"\"\n",
    "    if high < low:\n",
    "        return high + 1\n",
    "    else:\n",
    "        mid = (low + high) // 2\n",
    "        if self._table[mid]._key < k:\n",
    "            return self._find_index(k, mid + 1, high)\n",
    "        else:\n",
    "            return self._find_index(k, low, mid -1)\n",
    "\n",
    "# The find_index method as given in Code Fragment 10.8 does guarantee the result\n",
    "#  of identifying the index of the leftmost element with a key greater than or\n",
    "#  equal to the given key k in an array of distinct elements sorted in\n",
    "#  nondecreasing order. This guarantee is achieved because it returns the\n",
    "#  index where the element would be inserted to maintain the sorted order\n",
    "#  (if it's not already in the array). Since the method returns the index \n",
    "# of the leftmost element greater than or equal to k, it satisfies the desired \n",
    "# outcome.\n",
    "\n",
    "# On the other hand, the find_index method as given in Exercise R-10.21 does \n",
    "# not guarantee the result for finding the leftmost element greater than or \n",
    "# equal to k. The R-10.21 method returns the index of the rightmost occurrence \n",
    "# of an element equal to k in the array, or -1 if the element is not found.\n",
    "#  This method is specifically designed for locating the rightmost occurrence \n",
    "# of an element with key k, not for identifying the leftmost element greater\n",
    "#  than or equal to k. Therefore, it may not return the correct index for the\n",
    "#  desired purpose.\n",
    "\n",
    "# In summary:\n",
    "\n",
    "# Code Fragment 10.8's find_index method guarantees the correct\n",
    "#  result for finding the leftmost element greater than or equal to k.\n",
    "\n",
    "# Exercise R-10.21's find_index method is not suitable for this specific\n",
    "#  purpose, as it is intended for a different use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.40 \n",
    "# Suppose we are given two sorted search tables S and T, each with n entries\n",
    "# (with S and T being implemented with arrays). Describe an O(log^2 n) time\n",
    "#  algorithm for finding the kth smallest key in the union of the keys\n",
    "# from S and T (assuming no duplicates).\n",
    "\n",
    "# To find the kth smallest key in the union of two sorted arrays S and T, each with \n",
    "# n entries, you can use a modified binary search approach that achieves O(log^2 n)\n",
    "#  time complexity. Here's a high-level description of the algorithm:\n",
    "# \n",
    "# 1. Initialize two pointers, one for each array (S and T), and set them to point to \n",
    "# the first elements of their respective arrays.\n",
    "# \n",
    "# 2. Use binary search to find the middle element (median) of each array. Let's call\n",
    "#  them mid_S for array S and mid_T for array T.\n",
    "# \n",
    "# 3. Compare mid_S and mid_T. If mid_S is less than mid_T, it means that the kth smallest \n",
    "# element cannot be in the first half of array S, or the second half of array T.\n",
    "#  Conversely, if mid_S is greater than mid_T, it means that the kth smallest element\n",
    "#  cannot be in the first half of array T, or the second half of array S.\n",
    "# \n",
    "# 4. Based on the comparison result, you can eliminate approximately half of the \n",
    "# elements from one of the arrays. For example, if mid_S is smaller than mid_T, you\n",
    "#  can discard the first half of array S and reduce the problem to finding the  \n",
    "# (k - len(S) / 2)-th smallest element in the remaining part of array S and the\n",
    "#  entire array T. If mid_S is greater, you discard the appropriate elements in\n",
    "#  array T instead.\n",
    "# \n",
    "# 5. Recursively repeat steps 2-4 with the reduced subproblems until you find the\n",
    "#  kth smallest element.\n",
    "\n",
    "# Here is a Python Like Pseudo code\n",
    "\n",
    "def kth_smallest_in_sorted_arrays(S, T, k):\n",
    "    if len(S) == 0:\n",
    "        return T[k]\n",
    "    if len(T) == 0:\n",
    "        return S[k]\n",
    "    \n",
    "    mid_S = S[len(S) // 2]\n",
    "    mid_T = T[len(T) // 2]\n",
    "    \n",
    "    if mid_S < mid_T:\n",
    "        if k <= len(S) // 2 + len(T) // 2:\n",
    "            return kth_smallest_in_sorted_arrays(S, T[:len(T) // 2], k)\n",
    "        else:\n",
    "            return kth_smallest_in_sorted_arrays(S[len(S) // 2 + 1:], T, k - len(T) // 2 - 1)\n",
    "    else:\n",
    "        if k <= len(S) // 2 + len(T) // 2:\n",
    "            return kth_smallest_in_sorted_arrays(S[:len(S) // 2], T, k)\n",
    "        else:\n",
    "            return kth_smallest_in_sorted_arrays(S, T[len(T) // 2 + 1:], k - len(S) // 2 - 1)\n",
    "\n",
    "# The algorithm divides the problem into smaller subproblems and discards approximately \n",
    "# half of the elements in each step, resulting in a time complexity of O(log^2 n), where\n",
    "#  n is the size of the input arrays S and T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this needs work\n",
    "\n",
    "# C-10.41 Give an O(log n)-time solution for the previous problem.\n",
    "\n",
    "# To find the kth smallest key in the union of two sorted arrays S and T, each \n",
    "# with n entries, in O(log n) time, you can use a modified binary search approach.\n",
    "#  Here's the algorithm:\n",
    "\n",
    "# 1. Initialize two pointers, left_S and left_T, to the beginning of arrays S and\n",
    "#  T, respectively, and set k to the desired rank of the element.\n",
    "# \n",
    "# 2. Perform a binary search on the range [1, n] to find the kth smallest element.\n",
    "#  In each step of the binary search, do the following:\n",
    "# \n",
    "#   a. Calculate the mid-rank as mid = (left_S + left_T) // 2.\n",
    "# \n",
    "#   b. Calculate the mid-elements mid_S and mid_T corresponding to the mid-rank in\n",
    "#  arrays S and T, respectively.\n",
    "# \n",
    "#   c. If mid_S is less than mid_T, it means the kth smallest element is in the \n",
    "# range of elements before mid_S in array S and before mid_T in array T. Adjust\n",
    "#  left_S accordingly: left_S = mid + 1.\n",
    "# \n",
    "#   d. If mid_T is less than or equal to mid_S, it means the kth smallest element\n",
    "#  is in the range of elements before mid_T in array T and before mid_S in array S.\n",
    "#  Adjust left_T accordingly: left_T = mid + 1.\n",
    "# \n",
    "# 3. Continue the binary search until you find the kth smallest element. The final\n",
    "#  value of mid_S or mid_T will be the kth smallest element in the union of arrays\n",
    "#  S and T.\n",
    "\n",
    "def kthSmallestInSortedArrays(S, T, k):\n",
    "    n = len(S)\n",
    "    low, high = 0, n - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        count = mid + 1  # Count of elements in the current search range\n",
    "        \n",
    "        if S[mid] < T[mid]:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "        \n",
    "        if count >= k:\n",
    "            return min(S[mid], T[mid])\n",
    "    \n",
    "    # If k exceeds the total number of elements in both arrays, return -1 or handle it as needed.\n",
    "    return -1  # Indicates an invalid k value\n",
    "\n",
    "\n",
    "# This algorithm performs a binary search on the rank of the kth smallest element, reducing\n",
    "#  the search range by half in each step. Therefore, it runs in O(log n) time, where\n",
    "#  n is the size of the input arrays S and T.\n",
    "\n",
    "\n",
    "S = [2, 4, 7, 9, 11]\n",
    "T = [1, 3, 6, 8, 10]\n",
    "k = 5\n",
    "\n",
    "result = kthSmallestInSortedArrays(S, T, k)\n",
    "print(result)  # Expected output: 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's in the array: 21\n"
     ]
    }
   ],
   "source": [
    "# C-10.42 \n",
    "\n",
    "# Suppose that each row of an n×n array A consists of 1’s and 0’s such that,\n",
    "# in any row of A, all the 1’s come before any 0’s in that row. Assuming A\n",
    "# is already in memory, describe a method running in O(n log n) time (not\n",
    "# O(n^2) time!) for counting the number of 1’s in A.\n",
    "\n",
    "# [1,1,1,1,1,0]\n",
    "# [1,1,1,1,0,0]\n",
    "# [1,1,1,1,0,0]\n",
    "# [1,1,1,0,0,0]\n",
    "# [1,1,1,0,0,0]\n",
    "# [1,1,0,0,0,0]\n",
    "\n",
    "# i think the solution is about skip lists\n",
    "\n",
    "# You can indeed solve this problem using a modified binary search technique, which\n",
    "#  is somewhat similar to how skip lists work. Here's an algorithm to count the\n",
    "#  number of 1's in the given n×n array A in O(n log n) time:\n",
    "\n",
    "# Start with the top-right element of the array A, which is A[0][n-1]. Initialize\n",
    "#  two variables, row and col, to 0 and n-1, respectively. These variables \n",
    "# represent the current row and column you are checking.\n",
    "\n",
    "# Initialize a variable count to 0, which will be used to keep track of the count of 1's.\n",
    "\n",
    "# Repeat the following steps until row becomes n or col becomes -1 (i.e., until \n",
    "# you have checked all elements in the array):\n",
    "\n",
    "# a. If A[row][col] is 1, it means there are 1's to the left of this element, so\n",
    "#  increment count by col + 1 (the number of 1's in the current row) and move\n",
    "#  to the next row by incrementing row by 1.\n",
    "\n",
    "# b. If A[row][col] is 0, it means you need to move to the previous column by\n",
    "#  decrementing col by 1.\n",
    "\n",
    "# After the loop, count will contain the total count of 1's in the array A.\n",
    "\n",
    "# The key idea here is that by starting at the top-right element and making\n",
    "#  decisions based on the values encountered, you can efficiently traverse the\n",
    "#  array while counting the 1's. Since you visit each element in the array\n",
    "#  once, the algorithm runs in O(n log n) time.\n",
    "\n",
    "def count_ones_in_sorted_array(A):\n",
    "    n = len(A)\n",
    "    row, col = 0, n - 1\n",
    "    count = 0\n",
    "\n",
    "    while row < n and col >= 0:\n",
    "        if A[row][col] == 1:\n",
    "            count += col + 1  # Increment count by the number of 1's in the current row\n",
    "            row += 1  # Move to the next row\n",
    "        else:\n",
    "            col -= 1  # Move to the previous column\n",
    "    \n",
    "    return count\n",
    "\n",
    "# This algorithm efficiently counts the 1's in the given array while avoiding unnecessary traversals\n",
    "#  of 0's, resulting in a time complexity of O(n log n).\n",
    "\n",
    "# Example 2D array (6x6) with sorted rows\n",
    "array_A = [\n",
    "    [1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "# Count the number of 1's in the array\n",
    "count = count_ones_in_sorted_array(array_A)\n",
    "\n",
    "# Expected result: There are 21 occurrences of 1 in the array.\n",
    "print(\"Number of 1's in the array:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Pairs (Cost, Performance):\n",
      "Cost: 100, Performance: 50\n",
      "Cost: 150, Performance: 59\n",
      "Cost: 180, Performance: 58\n",
      "Cost: 200, Performance: 60\n",
      "Cost: 250, Performance: 70\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Genius\"\"\"\n",
    "\n",
    "# C-10.43 \n",
    "# Given a collection C of n cost-performance pairs (c, p), describe an \n",
    "# algorithm for finding the maxima pairs of C in O(nlog n) time.\n",
    "\n",
    "# To find the maximum pairs (c, p) from a collection C of n cost-performance \n",
    "# pairs in O(n log n) time, you can use the following algorithm, which is \n",
    "# based on sorting:\n",
    "\n",
    "# Make a list of pairs (c, p) from the collection C.\n",
    "\n",
    "# Sort the list of pairs in non-decreasing order of performance (p). This can\n",
    "#  be done using a stable sorting algorithm, such as mergesort or Timsort, which\n",
    "#  has a time complexity of O(n log n).\n",
    "\n",
    "# Initialize a variable max_c to the minimum possible cost (e.g., negative infinity).\n",
    "\n",
    "# Initialize an empty list max_pairs to store the maximum pairs.\n",
    "\n",
    "# Iterate through the sorted list of pairs from highest performance (end of the list) to\n",
    "#  lowest performance (beginning of the list):\n",
    "\n",
    "# a. For each pair (c, p), if c is greater than max_c, add (c, p) to max_pairs and \n",
    "# update max_c to c.\n",
    "\n",
    "# The max_pairs list will now contain the maximum pairs of (c, p) based on their \n",
    "# performance, and max_c will contain the maximum cost among those pairs.\n",
    "\n",
    "# This algorithm guarantees that you find the maximum pairs based on performance\n",
    "#  while keeping track of the maximum cost. The sorting step dominates the time\n",
    "#  complexity, resulting in O(n log n) time complexity for the entire algorithm.\n",
    "\n",
    "# this is cool, but it doesnt work.\n",
    "def find_maximum_pairs_(computer_parts):\n",
    "    # Sort the list of pairs based on performance (ascending order)\n",
    "    sorted_parts = sorted(computer_parts, key=lambda x: x[1])\n",
    "\n",
    "    max_cost = float('-inf')\n",
    "    max_pairs = []\n",
    "\n",
    "    # Iterate through sorted pairs\n",
    "    for cost, performance in sorted_parts:\n",
    "        if cost > max_cost:\n",
    "            max_pairs.append((cost, performance))\n",
    "            max_cost = cost\n",
    "\n",
    "    return max_pairs\n",
    "    \n",
    "def find_maximum_pairs(computer_parts):\n",
    "    # Make a dictionary to store the maximum performance for each cost\n",
    "    max_performance_dict = {}\n",
    "\n",
    "    # Iterate through the computer parts\n",
    "    for cost, performance in computer_parts:\n",
    "        if cost not in max_performance_dict or performance > max_performance_dict[cost]:\n",
    "            max_performance_dict[cost] = performance\n",
    "\n",
    "    # Make a list of maximum pairs based on the dictionary\n",
    "    max_pairs = [(cost, perf) for cost, perf in max_performance_dict.items()]\n",
    "    # Sort the maximum pairs based on cost in ascending order\n",
    "    max_pairs.sort(key=lambda x: x[0])\n",
    "\n",
    "    return max_pairs\n",
    "\n",
    "# Example usage:\n",
    "computer_parts = [\n",
    "    (100, 50),\n",
    "    (200, 60),\n",
    "    (150, 55),\n",
    "    (150, 58),\n",
    "    (150, 59),\n",
    "    (250, 70),\n",
    "    (180, 58)\n",
    "]\n",
    "\n",
    "max_pairs = find_maximum_pairs(computer_parts)\n",
    "\n",
    "print(\"Maximum Pairs (Cost, Performance):\")\n",
    "for cost, performance in max_pairs:\n",
    "    print(f\"Cost: {cost}, Performance: {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.44 \n",
    "\n",
    "# Show that the methods above(p) and prev(p) are not actually needed to\n",
    "# efficiently implement a map using a skip list. \n",
    "# \n",
    "# That is, we can implement  insertions and deletions in a skip list using a \n",
    "# strictly top-down, scan-forward approach, without ever using the above or prev methods. (Hint:\n",
    "# In the insertion algorithm, first repeatedly flip the coin to determine the\n",
    "# level where you should start inserting the new entry.\n",
    "\n",
    "# The above(p) and prev(p) methods in a skip list are used to efficiently navigate and search\n",
    "#  the skip list. While they can be helpful, they are not strictly necessary to implement \n",
    "# insertions and deletions in a skip list. You can indeed implement these operations using\n",
    "#  a top-down, scan-forward approach without explicitly using above(p) or prev(p) methods. \n",
    "# Here's a high-level overview of how you can achieve this:\n",
    "\n",
    "# Insertion in a Skip List:\n",
    "# \n",
    "# 1. Start from the top-level of the skip list.\n",
    "\n",
    "# 2. Flip a coin to determine the level where you should start inserting the new entry. \n",
    "\n",
    "# 3. This is essentially simulating the use of above(p) without directly calling it.\n",
    "\n",
    "# 4. Traverse the skip list from the top to the bottom while keeping track of the nodes \n",
    "# visited at each level.\n",
    "\n",
    "# 5. At each level, check if the next node's key is greater than the key of the element\n",
    "#  you want to insert. If it is, insert the new element before that node. If not, continue\n",
    "#  moving forward.\n",
    "# When you reach the bottom level, insert the new element into the bottom-level list.\n",
    "\n",
    "# Deletion in a Skip List:\n",
    "\n",
    "# 1. Start from the top-level of the skip list.\n",
    "\n",
    "# 2. Traverse the skip list from the top to the bottom while keeping track of the nodes\n",
    "#  visited at each level.\n",
    "# 3. At each level, check if the next node's key matches the key of the element you want \n",
    "# to delete. If it does, remove the reference to that node. If not, continue moving forward.\n",
    "\n",
    "# 4. When you reach the bottom level, you have deleted the element from the skip list.\n",
    "\n",
    "# By following this approach, you can insert and delete elements in a skip list without\n",
    "#  explicitly using above(p) or prev(p) methods. The coin-flipping mechanism and the\n",
    "#  top-down scan-forward traversal allow you to efficiently navigate and modify the \n",
    "# skip list structure.\n",
    "\n",
    "# These methods ensure that you maintain the skip list's structure and properties \n",
    "# while performing insertions and deletions efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.45 \n",
    "# Describe how to modify a skip-list representation so that index-based\n",
    "# operations, such as retrieving the item at index j, can be performed in\n",
    "# O(log n) expected time.\n",
    "\n",
    "# To modify a skip-list representation to support index-based operations \n",
    "# in O(log n) expected time, you can use a variant known as an \"indexed skip\n",
    "#  list\" or \"indexed skip list with levels.\" \n",
    "\n",
    "# Here's how you can achieve this:\n",
    "\n",
    "# 1. Augment Each Node with Size Information:\n",
    "\n",
    "#   - Each node in the skip list should store additional information about the \n",
    "# size of the sublist below it. This information represents the number of \n",
    "# nodes in the sublist that can be reached by following the forward pointers.\n",
    "\n",
    "# 2. Build a Forward Index:\n",
    "\n",
    "#   - Maintain a separate index that stores pointers to nodes at regular intervals. \n",
    "# These intervals should be determined based on the total size of the skip list.\n",
    "\n",
    "#   - For example, you can maintain an index for every 1/4th or 1/8th of the total size.\n",
    "\n",
    "# 3. Perform Index-Based Operations:\n",
    "\n",
    "#   - To retrieve the item at index j, start at the top-left corner of the skip list (the head).\n",
    "\n",
    "#   - Initialize an index variable to zero.\n",
    "\n",
    "#   - Traverse the skip list from the top level to the bottom level, always moving forward \n",
    "# to the next node.\n",
    "\n",
    "#  -  As you move, check the size information of the current node. If adding its size to the\n",
    "#  index variable keeps you below or equal to j, move to that node and increment the index\n",
    "#  variable by the node's size.\n",
    "\n",
    "#  -  Continue this process until you reach the bottom level.\n",
    "\n",
    "#   - Once you reach the bottom level, you'll have found the node that corresponds \n",
    "# to the item at index j.\n",
    "\n",
    "# 4. Efficiency Analysis:\n",
    "\n",
    "#   - With this modification, index-based operations, such as retrieving the item at\n",
    "#  index j, can be performed in O(log n) expected time.\n",
    "\n",
    "#   - The use of the forward index allows you to skip larger portions of the skip\n",
    "#  list, reducing the number of nodes you need to traverse.\n",
    "\n",
    "# By maintaining size information and a forward index, you can efficiently support\n",
    "#  index-based operations while still benefiting from the skip list's overall\n",
    "#  structure, which ensures logarithmic expected time complexity for \n",
    "# searching, insertion, and deletion operations.\n",
    "\n",
    "# This modification strikes a balance between maintaining the skip list's inherent\n",
    "#  properties and enabling efficient index-based operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A set object with elements [1, 2, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# C-10.46 \n",
    "# For sets S and T, the syntax S ˆ T returns a new set that is the \n",
    "# symmetric difference, that is, a set of elements that are in precisely one of S or T. \n",
    "# This syntax is supported by the special xor method. Provide an\n",
    "# implementation of that method in the context of the MutableSet abstract\n",
    "# base class, relying only on the five primary abstract methods of that class.\n",
    "\n",
    "from collections.abc import MutableSet\n",
    "\n",
    "class MySet(MutableSet):\n",
    "    def __init__(self, iterable=None):\n",
    "        self.elements = set()\n",
    "        if iterable is not None:\n",
    "            # update method for sets. \n",
    "            self |= set(iterable)\n",
    "\n",
    "    def __contains__(self, value):\n",
    "        return value in self.elements\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.elements)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "\n",
    "    def add(self, value):\n",
    "        self.elements.add(value)\n",
    "\n",
    "    def discard(self, value):\n",
    "        self.elements.discard(value)\n",
    "\n",
    "    def __xor__(self, other):\n",
    "        # Make a new set to store the symmetric difference\n",
    "        result = MySet(self)\n",
    "\n",
    "        # Remove elements that are in both sets (intersection)\n",
    "        for element in other:\n",
    "            if element in result:\n",
    "                result.discard(element)\n",
    "            else:\n",
    "                result.add(element)\n",
    "\n",
    "        # Remove elements that are in the original set\n",
    "        for element in self:\n",
    "            if element in other:\n",
    "                result.discard(element)\n",
    "            else:\n",
    "                result.add(element)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"A set object with elements {[elem for elem in iter(self)]}\"\n",
    "\n",
    "# Example usage:\n",
    "set1 = MySet([1, 2, 3, 4, 5])\n",
    "set2 = MySet([3, 4, 5, 6, 7])\n",
    "\n",
    "result = set1 ^ set2  # Calculate the symmetric difference\n",
    "print(result)  # Output: {1, 2, 6, 7}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "# C-10.47 \n",
    "\n",
    "# In the context of the MutableSet abstract base class, describe a concrete\n",
    "# implementation of the and method, which supports the syntax S & T \n",
    "# for computing the intersection of two existing sets\n",
    "\n",
    "from collections.abc import MutableSet\n",
    "\n",
    "class MySet(MutableSet):\n",
    "    def __init__(self, iterable=None):\n",
    "        self.elements = set()\n",
    "        if iterable is not None:\n",
    "            self |= set(iterable)\n",
    "\n",
    "    def __contains__(self, value):\n",
    "        return value in self.elements\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.elements)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "\n",
    "    def add(self, value):\n",
    "        self.elements.add(value)\n",
    "\n",
    "    def discard(self, value):\n",
    "        self.elements.discard(value)\n",
    "\n",
    "    def __and__(self, other_set):\n",
    "        # Make a new set to store the intersection\n",
    "        intersection = MySet()\n",
    "        \n",
    "        # Iterate through the elements in self and check if they are in other_set\n",
    "        for elem in self.elements:\n",
    "            if elem in other_set:\n",
    "                intersection.add(elem)\n",
    "        \n",
    "        return intersection\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.elements)\n",
    "\n",
    "set1 = MySet([1, 2, 3, 4, 5])\n",
    "set2 = MySet([3, 4, 5, 6, 7])\n",
    "\n",
    "intersection_set = set1 & set2\n",
    "print(intersection_set)  # Output: {3, 4, 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.48 \n",
    "\n",
    "# An inverted file is a critical data structure for implementing a search engine\n",
    "#  or the index of a book. Given a document D, which can be viewed\n",
    "# as an unordered, numbered list of words, an inverted file is an ordered list\n",
    "# of words, L, such that, for each word w in L, we store the indices of the\n",
    "# places in D where w appears. Design an efficient algorithm for constructing L from D.\n",
    "\n",
    "# To construct an inverted file, you can use a combination of data structures to efficiently \n",
    "# Make an ordered list of words, L, along with the indices of places in D where each word\n",
    "#  appears. Here's an algorithm to achieve this:\n",
    "# \n",
    "# 1) Initialize an empty dictionary inverted_file, where the keys are words, and the values\n",
    "#  are sets to store the indices of places where each word appears. Initialize an empty list\n",
    "#  word_list to store the ordered list of words.\n",
    "# \n",
    "# 2) Split the document D into words. You can do this by splitting the document using spaces\n",
    "#  or any other delimiter, and removing punctuation marks.\n",
    "# \n",
    "# 3) Iterate through the words in D along with their indices. Keep track of the current index\n",
    "#  as you iterate.\n",
    "# \n",
    "# 4) For each word encountered at index i, check if it exists in the inverted_file dictionary.\n",
    "#  If it doesn't exist, Make a new entry with the word as the key and initialize an empty\n",
    "#  set as the value. Append the word to the word_list.\n",
    "#  \n",
    "# 5) Add the current index i to the set associated with the word in the inverted_file dictionary.\n",
    "# \n",
    "# 6) Repeat steps 4 and 5 for all words in the document.\n",
    "# \n",
    "# 7) After processing all words in the document, sort the word_list in lexicographic \n",
    "# (or other desired) order.\n",
    "# \n",
    "# 8) You now have an ordered list of words L, and for each word, you have a set of indices\n",
    "#  indicating where it appears in the document. This forms the inverted file.\n",
    "\n",
    "def construct_inverted_file(document):\n",
    "    inverted_file = {}\n",
    "    word_list = []\n",
    "    \n",
    "    # Split the document into words and process them along with their indices\n",
    "    words = document.split()  # You can modify the splitting logic as needed\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        # Remove punctuation marks (you may need more sophisticated processing)\n",
    "        word = word.strip('.,!?()[]{}\":;')\n",
    "        \n",
    "        if word not in inverted_file:\n",
    "            inverted_file[word] = set()\n",
    "            word_list.append(word)\n",
    "        \n",
    "        inverted_file[word].add(i)\n",
    "    \n",
    "    # Sort the word_list\n",
    "    word_list.sort()\n",
    "    \n",
    "    return word_list, inverted_file\n",
    "\n",
    "# Example usage:\n",
    "document = \"This is a sample document. It contains words. Words appear in this document.\"\n",
    "word_list, inverted_file = construct_inverted_file(document)\n",
    "\n",
    "# Print the ordered list of words and the inverted file\n",
    "print(\"Ordered List of Words (L):\", word_list)\n",
    "print(\"\\nInverted File:\")\n",
    "for word in word_list:\n",
    "    print(f\"{word}: {inverted_file[word]}\")\n",
    "\n",
    "# This algorithm efficiently constructs an ordered list of words and the associated inverted \n",
    "# file with the indices where each word appears in the document. The resulting data \n",
    "# structures can be used for various text retrieval tasks, such as search engines\n",
    "#  or book indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-10.49 \n",
    "\n",
    "# Python’s collections module provides an OrderedDict class that is unrelated\n",
    "#  to our sorted map abstraction. An OrderedDict is a subclass of the\n",
    "# standard hash-based dict class that retains the expected O(1) performance\n",
    "# for the primary map operations, but that also guarantees that the iter\n",
    "# method reports items of the map according to first-in, first-out (FIFO)\n",
    "# order. That is, the key that has been in the dictionary the longest is reported\n",
    "#  first. (The order is unaffected when the value for an existing key\n",
    "# is overwritten.) Describe an algorithmic approach for achieving such performance.\n",
    "\n",
    "# To achieve the behavior of an OrderedDict in Python, which guarantees first-in,\n",
    "#  first-out (FIFO) order for iterating through items, you can implement a custom\n",
    "#  data structure that combines the functionality of a hash table and a doubly\n",
    "#  linked list. The linked list will keep track of the order of insertion for items.\n",
    "# \n",
    "# Here's an algorithmic approach to implement this custom OrderedDict-like data structure:\n",
    "# \n",
    "# Make a class, let's call it OrderedDictCustom, which will have the following attributes:\n",
    "# \n",
    "# A hash table (dictionary) to store key-value pairs.\n",
    "# A doubly linked list to maintain the order of insertion.\n",
    "# Define a node structure for the doubly linked list. Each node should store the\n",
    "#  key, value, and references to the previous and next nodes.\n",
    "# \n",
    "# Implement the following methods for OrderedDictCustom:\n",
    "# \n",
    "# __init__: Initialize the hash table and Make a dummy head and tail for the doubly linked list.\n",
    "\n",
    "# __getitem__: Retrieve the value for a given key from the hash table.\n",
    "\n",
    "# __setitem__: Add or update a key-value pair in the hash table. Also, update the linked list\n",
    "#  to maintain the order of insertion.\n",
    "\n",
    "# __delitem__: Remove a key-value pair from the hash table. Update the linked list\n",
    "#  to remove the corresponding node.\n",
    "\n",
    "# __iter__: Iterate through the linked list in FIFO order, starting from the\n",
    "#  dummy head node.\n",
    "\n",
    "# __len__: Return the number of key-value pairs in the hash table.\n",
    "\n",
    "# Optionally, add other methods as needed, such as keys, values, etc., to match the\n",
    "#  behavior of Python's dict.\n",
    "\n",
    "# When adding a new key-value pair to the dictionary using __setitem__, Make a \n",
    "# new node and insert it at the end of the linked list (before the dummy tail node).\n",
    "#  This ensures that the most recently added item is at the end of the list, and\n",
    "#  the oldest item is at the beginning.\n",
    "# \n",
    "# When removing a key-value pair using __delitem__, find the corresponding node\n",
    "#  in the linked list and remove it. Update the references of the previous and\n",
    "#  next nodes accordingly.\n",
    "# \n",
    "# When iterating through the items using __iter__, start from the dummy head\n",
    "#  node and move to the next node in the list until you reach the dummy tail\n",
    "#  node. This will give you items in FIFO order.\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "\n",
    "class OrderedDictCustom:\n",
    "    def __init__(self):\n",
    "        self.hash_table = {}\n",
    "        self.head = Node(None, None)  # Dummy head\n",
    "        self.tail = Node(None, None)  # Dummy tail\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.hash_table:\n",
    "            node = self.hash_table[key]\n",
    "            return node.value\n",
    "        raise KeyError(f\"Key not found: {key}\")\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self.hash_table:\n",
    "            # Update existing key\n",
    "            node = self.hash_table[key]\n",
    "            node.value = value\n",
    "        else:\n",
    "            # Insert a new key\n",
    "            node = Node(key, value)\n",
    "            self.hash_table[key] = node\n",
    "            # Insert the new node at the end of the linked list\n",
    "            prev_tail = self.tail.prev\n",
    "            prev_tail.next = node\n",
    "            node.prev = prev_tail\n",
    "            node.next = self.tail\n",
    "            self.tail.prev = node\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        if key in self.hash_table:\n",
    "            node = self.hash_table[key]\n",
    "            del self.hash_table[key]\n",
    "            # Remove the node from the linked list\n",
    "            prev_node = node.prev\n",
    "            next_node = node.next\n",
    "            prev_node.next = next_node\n",
    "            next_node.prev = prev_node\n",
    "        else:\n",
    "            raise KeyError(f\"Key not found: {key}\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        current = self.head.next\n",
    "        while current != self.tail:\n",
    "            yield current.key\n",
    "            current = current.next\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hash_table)\n",
    "\n",
    "# Example usage:\n",
    "ordered_dict = OrderedDictCustom()\n",
    "ordered_dict[\"apple\"] = 1\n",
    "ordered_dict[\"banana\"] = 2\n",
    "ordered_dict[\"cherry\"] = 3\n",
    "\n",
    "for key in ordered_dict:\n",
    "    print(key, ordered_dict[key])  # Outputs in FIFO order: apple, banana, cherry\n",
    "\n",
    "# This custom OrderedDict-like data structure maintains the order of insertion\n",
    "#  while providing O(1) time complexity for basic operations.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Not right now.\"\"\"\n",
    "\n",
    "# P-10.50 \n",
    "\n",
    "# Perform a comparative analysis that studies the collision rates for various\n",
    "# hash codes for character strings, such as various polynomial hash codes\n",
    "# for different values of the parameter a. Use a hash table to determine\n",
    "# collisions, but only count collisions where different strings map to the\n",
    "# same hash code (not if they map to the same location in this hash table).\n",
    "# Test these hash codes on text files found on the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Not right now.\"\"\"\n",
    "\n",
    "# P-10.51 \n",
    "# Perform a comparative analysis as in the previous exercise, but for 10-digit\n",
    "# telephone numbers instead of character strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# P-10.52 \n",
    "# Implement an OrderedDict class, as described in Exercise C-10.49, \n",
    "# ensuring that the primary map operations run in O(1) expected time.\n",
    "\n",
    "# To implement an OrderedDict class that guarantees O(1) expected time for\n",
    "#  primary map operations, you can use a combination of a hash table and a\n",
    "#  doubly linked list. This approach ensures that key-value pairs are \n",
    "# stored in the order they were added and allows for efficient\n",
    "#  insertion, deletion, and retrieval.\n",
    "\n",
    "class ListNode:\n",
    "    def __init__(self, key=None, value=None):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "\n",
    "class OrderedDict:\n",
    "    def __init__(self):\n",
    "        self.hash_map = {}\n",
    "        self.head = ListNode()\n",
    "        self.tail = ListNode()\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "\n",
    "    def _move_to_end(self, node):\n",
    "        # Move the given node to the end of the linked list\n",
    "        prev_node = node.prev\n",
    "        next_node = node.next\n",
    "\n",
    "        prev_node.next = next_node\n",
    "        next_node.prev = prev_node\n",
    "\n",
    "        node.prev = self.tail.prev\n",
    "        node.next = self.tail\n",
    "\n",
    "        self.tail.prev.next = node\n",
    "        self.tail.prev = node\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key not in self.hash_map:\n",
    "            raise KeyError(key)\n",
    "\n",
    "        node = self.hash_map[key]\n",
    "        self._move_to_end(node)\n",
    "        return node.value\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self.hash_map:\n",
    "            node = self.hash_map[key]\n",
    "            node.value = value\n",
    "            self._move_to_end(node)\n",
    "        else:\n",
    "            new_node = ListNode(key, value)\n",
    "            self.hash_map[key] = new_node\n",
    "            new_node.prev = self.tail.prev\n",
    "            new_node.next = self.tail\n",
    "            self.tail.prev.next = new_node\n",
    "            self.tail.prev = new_node\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        if key not in self.hash_map:\n",
    "            raise KeyError(key)\n",
    "\n",
    "        node = self.hash_map[key]\n",
    "        del self.hash_map[key]\n",
    "        node.prev.next = node.next\n",
    "        node.next.prev = node.prev\n",
    "\n",
    "    def __iter__(self):\n",
    "        current = self.head.next\n",
    "        while current != self.tail:\n",
    "            yield current.key\n",
    "            current = current.next\n",
    "\n",
    "    def items(self):\n",
    "        return ((key, self[key]) for key in self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hash_map)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.hash_map\n",
    "\n",
    "    def move_to_end(self, key):\n",
    "        if key not in self.hash_map:\n",
    "            raise KeyError(key)\n",
    "\n",
    "        node = self.hash_map[key]\n",
    "        self._move_to_end(node)\n",
    "\n",
    "    def popitem(self, last=True):\n",
    "        if not self:\n",
    "            raise KeyError(\"OrderedDict is empty\")\n",
    "        key = self.tail.prev.key if last else self.head.next.key\n",
    "        del self[key]\n",
    "        return (key, self[key])\n",
    "\n",
    "    def pop(self, key, default=None):\n",
    "        if key in self.hash_map:\n",
    "            value = self[key]\n",
    "            del self[key]\n",
    "            return value\n",
    "        return default\n",
    "\n",
    "    def clear(self):\n",
    "        self.hash_map.clear()\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "\n",
    "    def keys(self):\n",
    "        return iter(self)\n",
    "\n",
    "    def values(self):\n",
    "        return (self[key] for key in self)\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        if args:\n",
    "            if len(args) > 1:\n",
    "                raise TypeError(\"update expected at most 1 argument, got %d\" % len(args))\n",
    "            other = args[0]\n",
    "            if hasattr(other, \"keys\"):\n",
    "                for key in other.keys():\n",
    "                    self[key] = other[key]\n",
    "            else:\n",
    "                for key, value in other:\n",
    "                    self[key] = value\n",
    "        for key in kwargs:\n",
    "            self[key] = kwargs[key]\n",
    "\n",
    "    def setdefault(self, key, default=None):\n",
    "        if key not in self:\n",
    "            self[key] = default\n",
    "        return self[key]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, OrderedDict):\n",
    "            return len(self) == len(other) and all(k1 == k2 and v1 == v2 for (k1, v1), (k2, v2) in zip(self.items(), other.items()))\n",
    "        return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self:\n",
    "            return \"%s()\" % (self.__class__.__name__,)\n",
    "        return \"%s(%r)\" % (self.__class__.__name__, self.items())\n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "\n",
    "# Example usage:\n",
    "od = OrderedDict()\n",
    "od['a'] = 1\n",
    "od['b'] = 2\n",
    "od['c'] = 3\n",
    "\n",
    "print([elem for elem in od.keys()])  # Output: ['a', 'b', 'c']\n",
    "print([next(od.values()) for _ in range(3)])   # Output: [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-10.53 \n",
    "# Design a Python class that implements the skip-list data structure. Use\n",
    "# this class to Make a complete implementation of the sorted map ADT.\n",
    "\n",
    "# Implementing a skip-list data structure from scratch is a complex task, and\n",
    "#  providing a complete implementation of the sorted map ADT using skip-lists\n",
    "#  in a single response is impractical. Instead, I'll provide a high-level\n",
    "#  overview of how you can design a Python class for a skip-list and suggest\n",
    "#  the steps to adapt it for use as a sorted map ADT.\n",
    "\n",
    "import random\n",
    "\n",
    "class SkipListNode:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.forward = []\n",
    "\n",
    "class SkipList:\n",
    "    def __init__(self):\n",
    "        self.head = SkipListNode(float('-inf'), None)\n",
    "        self.tail = SkipListNode(float('inf'), None)\n",
    "        self.head.forward = [self.tail]\n",
    "        self.max_level = 0\n",
    "\n",
    "    def random_level(self):\n",
    "        level = 1\n",
    "        while random.random() < 0.5 and level <= self.max_level:\n",
    "            level += 1\n",
    "        return level\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        node = self.head\n",
    "\n",
    "        for level in range(self.max_level, -1, -1):\n",
    "            while node.forward[level] and node.forward[level].key < key:\n",
    "                node = node.forward[level]\n",
    "            update[level] = node\n",
    "\n",
    "        level = self.random_level()\n",
    "\n",
    "        if level > self.max_level:\n",
    "            for i in range(self.max_level + 1, level + 1):\n",
    "                update.append(self.head)\n",
    "            self.max_level = level\n",
    "\n",
    "        new_node = SkipListNode(key, value)\n",
    "        new_node.forward = [None] * (level + 1)\n",
    "\n",
    "        for i in range(level + 1):\n",
    "            new_node.forward[i] = update[i].forward[i]\n",
    "            update[i].forward[i] = new_node\n",
    "\n",
    "    def delete(self, key):\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        node = self.head\n",
    "\n",
    "        for level in range(self.max_level, -1, -1):\n",
    "            while node.forward[level] and node.forward[level].key < key:\n",
    "                node = node.forward[level]\n",
    "            update[level] = node\n",
    "\n",
    "        if node.forward[0] and node.forward[0].key == key:\n",
    "            deleted_node = node.forward[0]\n",
    "            for level in range(len(deleted_node.forward)):\n",
    "                update[level].forward[level] = deleted_node.forward[level]\n",
    "            del deleted_node\n",
    "\n",
    "    def search(self, key):\n",
    "        node = self.head\n",
    "\n",
    "        for level in range(self.max_level, -1, -1):\n",
    "            while node.forward[level] and node.forward[level].key < key:\n",
    "                node = node.forward[level]\n",
    "\n",
    "        if node.forward[0] and node.forward[0].key == key:\n",
    "            return node.forward[0].value\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "# This code defines a basic skip-list data structure with insertion, deletion, and\n",
    "#  search operations. To adapt it for use as a sorted map ADT, you can store\n",
    "#  key-value pairs in the skip-list nodes, use the insert method for adding\n",
    "#  key-value pairs, and modify the search method to return values associated\n",
    "#  with keys. You can also implement additional map-related methods like\n",
    "#  __getitem__, __setitem__, __delitem__, and others to fully support the \n",
    "# sorted map ADT.\n",
    "\n",
    "# Please note that this is a simplified implementation, and skip-lists can\n",
    "#  become more complex as you add features and optimizations. A complete\n",
    "#  sorted map implementation would also include error handling, balancing, and\n",
    "# other features required for a practical data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A challange for later\"\"\"\n",
    "\n",
    "# P-10.54 \n",
    "# \n",
    "# Extend the previous project by providing a graphical animation of the\n",
    "# skip-list operations. Visualize how entries move up the skip list during\n",
    "# insertions and are linked out of the skip list during removals. Also, in a\n",
    "# search operation, visualize the scan-forward and drop-down actions.\n",
    "\n",
    "# Creating a graphical animation of skip-list operations is a more involved\n",
    "#  project that goes beyond simple text-based programming. To achieve this, you\n",
    "#  would need to use a graphical user interface (GUI) library like Tkinter, PyQt, or\n",
    "#  Pygame, which allows you to Make visual elements and animations.\n",
    "# \n",
    "# Here's a high-level overview of how you can approach this project using Python\n",
    "#  and a GUI library:\n",
    "# \n",
    "# Choose a GUI Library: Select a Python GUI library that suits your needs and skills. \n",
    "# Tkinter is the most straightforward choice for simple GUIs, while PyQt and Pygame\n",
    "#  offer more advanced features and flexibility.\n",
    "# \n",
    "# Make a Skip-List Visualization Class: Define a class that represents the skip-list \n",
    "# and handles its visualization. This class should include methods for \n",
    "# inserting, deleting, and searching for elements while updating the graphical\n",
    "#  representation.\n",
    "# \n",
    "# Visualize Insertions: When you insert an element into the skip-list, visually \n",
    "# represent the steps involved in choosing the level and updating the pointers. \n",
    "# Use animations to show how the new element moves up the levels.\n",
    "# \n",
    "# Visualize Deletions: When you delete an element, visualize how it is unlinked \n",
    "# from the skip-list structure. Use animations to demonstrate how the pointers \n",
    "# are adjusted.\n",
    "# \n",
    "# Visualize Searches: During a search operation, show how the algorithm scans \n",
    "# forward and drops down the levels as it searches for the target element. Highlight\n",
    "#  the visited nodes and display the path taken.\n",
    "# \n",
    "# Implement User Controls: Add buttons, sliders, or other user controls to interact\n",
    "#  with the skip-list, such as inserting, deleting, and searching for elements.\n",
    "# \n",
    "# Make an Animated GUI: Build the graphical user interface that displays the skip-list\n",
    "#  and responds to user input. Update the visualization in real-time as operations \n",
    "# are performed.\n",
    "# \n",
    "# Testing and Debugging: Test your graphical skip-list with various input scenarios\n",
    "#  to ensure that it behaves as expected and that the animations are accurate.\n",
    "# \n",
    "# Optimize and Refine: Optimize the animation speed, add labels and tooltips, and \n",
    "# refine the user interface to make it user-friendly and informative.\n",
    "# \n",
    "# Documentation and Presentation: Provide clear documentation for your project, explaining\n",
    "#  how to use it and how the animations work. Consider creating a presentation or demo\n",
    "#  to showcase your project's features.\n",
    "# \n",
    "# This project will require a solid understanding of both skip-list data structures and \n",
    "# GUI programming with the chosen library. It's a challenging but rewarding endeavor that\n",
    "#  combines data structure implementation with visualization and interaction. Depending \n",
    "# on your experience and goals, it may take some time to complete, but it can be a \n",
    "# valuable learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible corrections for 'aple': ['aple', 'asple', 'apled', 'caple', 'axple', 'kple', 'pple', 'apae', 'aplb', 'aplu', 'alle', 'apve', 'faple', 'avple', 'apmle', 'apleo', 'acle', 'aplve', 'aule', 'ople', 'apcle', 'aplc', 'aplv', 'ale', 'apleh', 'iple', 'aplue', 'aplo', 'uple', 'taple', 'apbe', 'apze', 'ayle', 'awle', 'aplm', 'ahple', 'aplec', 'qaple', 'aplke', 'ample', 'aplje', 'ahle', 'tple', 'nple', 'aiple', 'appe', 'apsle', 'apble', 'azle', 'aplx', 'waple', 'eaple', 'apde', 'apqe', 'adple', 'apse', 'apdle', 'apule', 'anple', 'ape', 'apole', 'apnle', 'apvle', 'aplj', 'aplhe', 'dple', 'akple', 'aplxe', 'aphle', 'uaple', 'apfle', 'aplez', 'anle', 'apre', 'atple', 'aplte', 'aale', 'aphe', 'apje', 'laple', 'apee', 'abple', 'apele', 'aplef', 'axle', 'aplie', 'aplee', 'adle', 'aply', 'apxe', 'apll', 'akle', 'aplew', 'kaple', 'aploe', 'bple', 'afle', 'apleb', 'aptle', 'baple', 'agple', 'aplce', 'aplei', 'arle', 'atle', 'aplge', 'aplh', 'apjle', 'aplea', 'zple', 'apqle', 'apke', 'aplex', 'daple', 'auple', 'apld', 'apgle', 'vple', 'agle', 'aplen', 'aples', 'aplye', 'iaple', 'raple', 'aplz', 'apile', 'apale', 'apxle', 'aplse', 'apoe', 'ajple', 'aople', 'asle', 'aplqe', 'aqle', 'aole', 'aplq', 'afple', 'sple', 'apla', 'yple', 'cple', 'aplne', 'aplw', 'apleg', 'apie', 'aplt', 'aprle', 'ajle', 'able', 'aplfe', 'apwle', 'alple', 'apye', 'azple', 'wple', 'aplme', 'aplet', 'apleu', 'eple', 'aplr', 'jple', 'paple', 'mple', 'vaple', 'saple', 'aplle', 'aplre', 'apte', 'haple', 'apkle', 'gaple', 'apl', 'apue', 'aplze', 'aplep', 'apge', 'aele', 'apne', 'yaple', 'aplde', 'xaple', 'aqple', 'aaple', 'aplpe', 'aplej', 'aplem', 'aplev', 'apli', 'apln', 'aplp', 'ayple', 'amle', 'aeple', 'apley', 'rple', 'apls', 'aplae', 'japle', 'arple', 'apyle', 'apfe', 'maple', 'aplel', 'acple', 'aplf', 'zaple', 'lple', 'aplg', 'aplek', 'ple', 'aile', 'aplk', 'avle', 'apleq', 'aplwe', 'gple', 'apple', 'apzle', 'oaple', 'fple', 'xple', 'apce', 'apme', 'aplbe', 'apler', 'hple', 'qple', 'apwe', 'naple', 'awple', 'pale', 'apel', 'alpe']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A challange for later\"\"\"\n",
    "\n",
    "# P-10.55 \n",
    "\n",
    "# Write a spell-checker class that stores a lexicon of words, W, in a Python\n",
    "# set, and implements a method, check(s), which performs a spell check\n",
    "# on the string s with respect to the set of words, W. \n",
    "# \n",
    "# If s is in W, then  the call to check(s) returns a list containing only s, as it is assumed to\n",
    "# be spelled correctly in this case. \n",
    "# \n",
    "# If s is not in W, then the call to check(s) returns a list of every word in\n",
    "#  W that might be a correct spelling of s. \n",
    "# \n",
    "# Your program should be able to handle all the common ways that s might be a\n",
    "# misspelling of a word in W, including swapping adjacent characters in a\n",
    "# word, inserting a single character in between two adjacent characters in a\n",
    "# word, deleting a single character from a word, and replacing a character in\n",
    "# a word with another character. For an extra challenge, consider phonetic\n",
    "# substitutions as well.\n",
    "\n",
    "# here is a simplified approach as a guide.\n",
    "\n",
    "# Implementing a spell-checker class that handles various types of misspellings\n",
    "#  is a complex task. Here's a Python class that provides basic functionality \n",
    "# for spell-checking using Levenshtein distance (edit distance) as a measure \n",
    "# for identifying possible correct spellings. The class uses a set of words as\n",
    "#  the lexicon.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SpellChecker:\n",
    "    def __init__(self, lexicon):\n",
    "        self.lexicon = set(lexicon)\n",
    "\n",
    "    def check(self, s):\n",
    "        if s in self.lexicon:\n",
    "            return [s]  # The word is correct, return it\n",
    "\n",
    "        # Generate possible corrections\n",
    "        candidates = self._generate_candidates(s)\n",
    "\n",
    "        # Calculate edit distances\n",
    "        distances = {word: self._edit_distance(s, word) for word in candidates}\n",
    "\n",
    "        # Sort candidates by edit distance (ascending)\n",
    "        sorted_candidates = sorted(candidates, key=lambda word: distances[word])\n",
    "\n",
    "        return sorted_candidates\n",
    "\n",
    "    def _generate_candidates(self, s):\n",
    "        # Generate possible corrections by swapping, inserting, deleting, and replacing characters\n",
    "        candidates = set()\n",
    "\n",
    "        # Swapping adjacent characters\n",
    "        for i in range(len(s) - 1):\n",
    "            swapped = s[:i] + s[i + 1] + s[i] + s[i + 2:]\n",
    "            candidates.add(swapped)\n",
    "\n",
    "        # Inserting a character\n",
    "        for i in range(len(s) + 1):\n",
    "            for c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                inserted = s[:i] + c + s[i:]\n",
    "                candidates.add(inserted)\n",
    "\n",
    "        # Deleting a character\n",
    "        for i in range(len(s)):\n",
    "            deleted = s[:i] + s[i + 1:]\n",
    "            candidates.add(deleted)\n",
    "\n",
    "        # Replacing a character\n",
    "        for i in range(len(s)):\n",
    "            for c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                replaced = s[:i] + c + s[i + 1:]\n",
    "                candidates.add(replaced)\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    def _edit_distance(self, word1, word2):\n",
    "        # Calculate Levenshtein distance between two words\n",
    "        m, n = len(word1), len(word2)\n",
    "        dp = np.zeros((m + 1, n + 1))\n",
    "\n",
    "        for i in range(m + 1):\n",
    "            dp[i][0] = i\n",
    "\n",
    "        for j in range(n + 1):\n",
    "            dp[0][j] = j\n",
    "\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                cost = 0 if word1[i - 1] == word2[j - 1] else 1\n",
    "                dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n",
    "\n",
    "        return dp[m][n]\n",
    "\n",
    "# Example usage:\n",
    "lexicon = [\"apple\", \"banana\", \"cherry\", \"grape\", \"orange\"]\n",
    "spell_checker = SpellChecker(lexicon)\n",
    "word = \"aple\"\n",
    "corrections = spell_checker.check(word)\n",
    "print(f\"Possible corrections for '{word}': {corrections}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('api_tryout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c91247f238ffe20a81ff6d7bbd78e8b7013835d5efca94aed45fabb2c8c2521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
